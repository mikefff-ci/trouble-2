commands:
  docker-login-jpio:
    description: Log into the docker registry at docker-registry.janusplatform.io
    parameters:
      docker-password:
        default: ARTIFACTORY_API_KEY
        description: Env var for the password to log into the docker registry
        type: env_var_name
      docker-user:
        default: ARTIFACTORY_USER
        description: Env var for the user to log into the docker registry
        type: env_var_name
    steps:
    - run:
        command: |
          # https://stackoverflow.com/a/51518255
          echo "${<< parameters.docker-password >>}" | docker login -u "${<< parameters.docker-user >>}"  --password-stdin docker-registry.janusplatform.io
        name: docker login
  ensure-repos:
    description: Ensures the existence and correct permissions on ECR repositories.
    parameters:
      account-url:
        default: AWS_ECR_ACCOUNT_URL
        description: Env var storing Amazon ECR account URL
        type: env_var_name
      ecr-access-policy-parameter-name:
        default: /janus/build/ecr/cross-account-access-policy
        description: The name of the param store parameter that contains ECR access policy
        type: string
      ecr-lifecycle-policy-parameter-name:
        default: /janus/build/ecr/lifecycle-policy
        description: The name of the param store parameter that contains ECR lifecycle policy
        type: string
      input-file-name:
        default: repos.txt
        description: Name of to file(s) listing repos to provision
        type: string
      repo:
        default: ''
        description: One or more full-URI repository names to create
        type: string
    steps:
    - when:
        condition: << parameters.repo >>
        steps:
        - run:
            command: |
              ensure-repositories-by-name.py << parameters.repo >> -a << parameters.ecr-access-policy-parameter-name >> -l << parameters.ecr-lifecycle-policy-parameter-name >>
            description: |
              Creates ECR repos if they don't exist, adding lifecycle and access policies.
            name: Execute ensure script with explicit input
    - unless:
        condition: << parameters.repo >>
        steps:
        - run:
            command: |
              cat $(find "/tmp/workspace/image-files/" -name << parameters.input-file-name >>) | ensure-repositories-by-name.py --access-policy << parameters.ecr-access-policy-parameter-name >> --lifecycle-policy << parameters.ecr-lifecycle-policy-parameter-name >>
            description: |
              Creates ECR repos if they don't exist, adding lifecycle and access policies.
            name: Execute ensure script from file input
  find-and-copy-deploy-spec:
    description: Find the janus .yml files and copy them to a single location for persisting
    parameters:
      deploy-spec-target-path:
        default: /tmp/workspace/janus_version
        description: Path to write version file
        type: string
    steps:
    - run:
        command: |
          if [[ -d .janus && -f .janus/deploy.yml ]]; then
              janus_config_path=".janus/deploy.yml"
          elif [[ -f JanusDeployment.yml ]]; then
              janus_config_path="JanusDeployment.yml"
          else
              if [[ $? -ne 0 ]]; then
                  echo "Unable to find any Janus deploy yaml file. Checked .janus/deploy and ./JanusDeployment.yml"
                  exit 13
              fi
          fi
          mkdir -p $(dirname << parameters.deploy-spec-target-path >>)
          cp $janus_config_path << parameters.deploy-spec-target-path >>

          # Copy over other existing yaml files, i.e. label.yml, notify.yml etc. except for deploy.yml which was already copied over
          if [[ -d .janus && $(find .janus -type f -not -name deploy.yml) ]]; then
              shopt -s extglob
              src=".janus/!(deploy.yml)"
              dest="/tmp/workspace/"
              cp -r $src $dest
          fi
        name: Find and copy deploy spec
  form-stack:
    description: Generate CloudFormation templates from normalized Janus deployment YAML
    parameters:
      base-input-context-path:
        default: /tmp/workspace/artifacts/Context/base-input-context.json
        type: string
      normalized-deploy-spec-path:
        default: /tmp/workspace/NormalizedJanusDeployment.yml
        description: Path to normalized deploy.yml
        type: string
      output-dir:
        default: /tmp/workspace/artifacts/
        description: Target path for generated CloudFormation templates
        type: string
    steps:
    - run:
        command: |
          mkdir -p /tmp/stack
          stack_zip=/tmp/stack/stack.zip

          # Concatenate base64 versions of input context and normalized deploy spec (stack-formation needs both)
          # TODO look into possibility of adding deploy spec to context file (for consistency with how the context is used elsewhere)
          echo $(base64 << parameters.base-input-context-path >>) > combined_input_and_context
          echo $(base64 << parameters.normalized-deploy-spec-path >>) >> combined_input_and_context
          # Commit hash is needed by stack-formation in order to populate the commit env var in the deployed stack, used in /env endpoint
          status_code=$(curl --silent --write-out %{http_code} -X POST -H "Content-Type: text/plain" -H "Accept: application/zip" -H "git-commit: $CIRCLE_SHA1" --data-binary @combined_input_and_context https://stack-formation-stack-formation-api.tools-prd.janusplatform.io/stack-formation/form-stack --output "${stack_zip}")
          # If any status code 400 or greater then bail
          if [ "${status_code}" -ge 400 ]; then
            echo "Exiting because the call to stack-formation-stack-formation-api.tools-prd.janusplatform.io/stack-formation/form-stack returned a ${status_code}"
            echo "The lambda response was - $(cat ${stack_zip})"
            exit 1
          fi

          # Is the zip not zippy?
          if ! zip -T "${stack_zip}" >/dev/null 2>&1; then
            echo "Exiting because the call to stack-formation-stack-formation-api.tools-prd.janusplatform.io/stack-formation/form-stack returned a malformed zip file"
            echo "The lambda response was - $(cat ${stack_zip})"
            exit 1
          fi

          cd << parameters.output-dir >>
          # Unzip the results. skip base-input-context.json as we already have it
          unzip "${stack_zip}" -x Context/base-input-context.json
        name: Stack formation
  generate-janus-context:
    description: Create the Context directory and populate with per-environment values
    parameters:
      aws-region:
        default: us-west-2
        description: Target aws region
        type: string
      deploy-spec-path:
        default: /tmp/workspace/deploy.yml
        description: Path to deploy.yml
        type: string
      output-dir:
        default: /tmp/workspace/artifacts/Context
        description: Path to Context
        type: string
      stack-name-path:
        default: /tmp/workspace/stack_name
        description: File containing the name of the stack being built
        type: string
      version-path:
        default: /tmp/workspace/janus_version
        description: File containing the version of the stack being built
        type: string
    steps:
    - run:
        command: |2

          set -ux
          declare -r janus_context_dir="<< parameters.output-dir >>"
          declare -r janus_context="<< parameters.output-dir >>/base-input-context.json"
          declare -r deploy_spec_base64=$(base64 << parameters.deploy-spec-path >> | tr -d '\n')
          declare -r janus_stack_version=$(cat << parameters.version-path >>)
          declare -r stack_name=$(cat << parameters.stack-name-path >>)
          declare -r aws_region="<< parameters.aws-region >>"


          # Ensure our own target locations are clean to start
          if [ -d "${janus_context_dir}" ]; then
              rm -rf "${janus_context_dir}"
          fi
          mkdir -p "${janus_context_dir}"

          cat >"${janus_context}"\<<EOF
          {
            "inputContext": [
              {
                "name": "git_commit",
                "type": "string",
                "fromString": "${CIRCLE_SHA1}"
              },
              {
                "name": "git_commit_url",
                "type": "string",
                "fromString": "https://github.com/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/commit/${CIRCLE_SHA1}"
              },
              {
                "name": "git_branch",
                "type": "string",
                "fromString": "${CIRCLE_BRANCH}"
              },
              {
                "name": "build_url",
                "type": "string",
                "fromString": "${CIRCLE_BUILD_URL}"
              },
              {
                "name": "vendor_ips",
                "type": "map",
                "fromMap": {
                  "internet": {
                    "type": "list",
                    "fromList": [
                        "199.83.128.0/21",
                        "198.143.32.0/19",
                        "149.126.72.0/21",
                        "103.28.248.0/22",
                        "45.64.64.0/22",
                        "185.11.124.0/22",
                        "192.230.64.0/18",
                        "107.154.0.0/16",
                        "45.60.0.0/16",
                        "45.223.0.0/16"
                      ]
                  },
                  "apigee": {
                    "type": "list",
                    "fromList": [
                        "54.218.18.60/32",
                        "54.213.191.225/32"
                    ]
                  },
                  "salesforce": {
                    "type": "list",
                    "fromList": [
                        "13.108.0.0/14",
                        "66.231.80.0/20",
                        "68.232.192.0/20",
                        "96.43.144.0/20",
                        "136.146.0.0/15",
                        "198.245.80.0/20",
                        "199.122.120.0/21",
                        "204.14.232.0/21"
                    ]
                  },
                  "cambia": {
                    "type": "list",
                    "fromList": [
                        "161.208.0.0/16",
                        "199.79.222.0/24",
                        "204.80.161.0/24",
                        "205.166.241.0/24"
                    ]
                  }
                }
              },
          EOF

          ## Add spec contents for other yaml files found in .janus directory
          if [[ $(find .janus -type f -not -name deploy.yml) ]]; then
            shopt -s extglob
            yaml_files="$(echo .janus/!(deploy.yml))"
            for file in $yaml_files
            do
              base_name="$(basename $file .yml)"
              declare -r ${base_name}_spec="/tmp/workspace/${base_name}.yml"
              base_name_spec="${base_name}_spec"
              declare -r ${base_name}_spec_base64=$(base64 ${!base_name_spec} | tr -d '\n')
              base_name_spec_base64="${base_name}_spec_base64"

              cat >>"${janus_context}"\<<EOF
              {
                "name": "${base_name}_spec",
                "type": "string",
                "fromLookup": {
                  "type": "json",
                  "base64": {
                    "value": "${!base_name_spec_base64}",
                    "type": "yaml"
                  }
                }
              },
          EOF
            done
          fi

          cat >>"${janus_context}"\<<EOF
              {
                "name": "deploy_spec",
                "type": "string",
                "fromLookup": {
                  "type": "json",
                  "base64": {
                    "value": "${deploy_spec_base64}",
                    "type": "yaml"
                  }
                }
              },
              {
                "name": "janus_stack_version",
                "type": "string",
                "fromString": "${janus_stack_version}"
              },
              {
                "name": "account_id",
                "type": "string",
                "fromLookup": {
                  "cloudformation": {
                    "name": "AccountId",
                    "type": "string"
                  }
                }
              },
              {
                "name": "environment",
                "type": "string",
                "fromLookup": {
                  "cloudformation": {
                    "name": "Environment",
                    "type": "string"
                  }
                }
              },
              {
                "name": "vpc_id",
                "type": "string",
                "fromLookup": {
                  "cloudformation": {
                    "name": "VpcId",
                    "type": "string"
                  }
                }
              },
              {
                "name": "private_subnets",
                "type": "list",
                "fromLookup": {
                  "cloudformation": {
                    "name": "PrivateSubnets",
                    "type": "list"
                  }
                }
              },
              {
                "name": "public_subnets",
                "type": "list",
                "fromLookup": {
                  "cloudformation": {
                    "name": "PublicSubnets",
                    "type": "list"
                  }
                }
              },
              {
                "name": "ssl_certificate_arn",
                "type": "string",
                "fromLookup": {
                  "cloudformation": {
                    "name": "JanusCertificateArn",
                    "type": "string"
                  }
                }
              },
              {
                "name": "environment_variables",
                "type": "map",
                "fromMap": {
                  "JANUS_STACK_NAME": {
                    "name": "JANUS_STACK_NAME",
                    "type": "string",
                    "fromString": "${stack_name}"
                  },
                  "JANUS_STACK_VERSION": {
                    "name": "JANUS_STACK_VERSION",
                    "type": "string",
                    "fromString": "${janus_stack_version}"
                  },
                  "AWS_REGION": {
                    "name": "AWS_REGION",
                    "type": "string",
                    "fromString": "${aws_region}"
                  }
                }
              }
            ]
          }
          EOF

          # Ensure the base-input-context.json is valid
          if ! jq -r . $janus_context >/dev/null 2>&1; then
            echo "Input context ${janus_context} is not valid JSON"
            echo "Start janus_context"
            cat $janus_context
            echo "End janus_context"
            exit 1
          fi
        name: Create Janus Context base-input-context.json
  generate-version:
    description: Generate Janus version (YYYYMMDD_HHmmSS) and persists `janus_version` file to workspace at <parameters.workspace_root>
    parameters:
      version-target-path:
        default: /tmp/workspace/janus_version
        description: Path to write version file
        type: string
    steps:
    - run:
        command: |
          mkdir -p $(dirname << parameters.version-target-path >>)
          echo "${TIMESTAMP:-`date +%Y%m%d_%H%M%S `}" > << parameters.version-target-path >>

          echo "JANUS_VERSION:$(cat << parameters.version-target-path >>)"
        name: Generate Janus timestamp version
  get-stack-name:
    description: Extract the stack-name from the deploy spec and save it to the workspace
    parameters:
      deploy-spec-path:
        default: /tmp/workspace/deploy.yml
        description: Path to deploy.yml
        type: string
      stack-name-target-path:
        default: /tmp/workspace/stack_name
        description: Path to write version file
        type: string
    steps:
    - run:
        command: |
          cat << parameters.deploy-spec-path >> | grep "^stack_name" | cut -d" " -f2 | sed -e 's/^"//' -e 's/"$//' > << parameters.stack-name-target-path >>
        echo "Found stack_name: $(cat << parameters.stack-name-target-path >>)"
        name: Extract stack_name
  normalize-deploy-spec:
    description: Transform deploy.yml for stack-formation. Adds janus_version, translates dockerfile references to ECR images, etc.
    parameters:
      context-dir:
        default: /tmp/workspace/artifacts/Context
        description: Path to Context
        type: string
      deploy-spec-path:
        default: /tmp/workspace/deploy.yml
        description: Path to deploy.yml
        type: string
      images-yml-path:
        default: image-files/containers/timestamp_images_output.yml
        description: Path to YML file of images to be consumed
        type: string
      output-path:
        default: /tmp/workspace/NormalizedJanusDeployment.yml
        description: Path to normalized deploy.yml
        type: string
      stack-name-path:
        default: /tmp/workspace/stack_name
        description: File containing the name of the stack being built
        type: string
      version-path:
        default: /tmp/workspace/janus_version
        description: File containing the version of the stack being built
        type: string
    steps:
    - run:
        command: |
          # Get the value of the RETAG env_var set in the extractor job; some stacks don't have extractor job, set RETAG true in that case.
          if [[ -f /tmp/workspace/env_var ]]; then
              source /tmp/workspace/env_var
          else
              RETAG=true
          fi

          set -x
          declare -r stack_name=$(cat << parameters.stack-name-path >>)
          declare -r janus_version=$(cat << parameters.version-path >>)
          declare -r janus_context="<< parameters.context-dir >>/base-input-context.json"

          normalize.py --janusconfig << parameters.deploy-spec-path >> --version $janus_version --stack-name $stack_name --imagesfile << parameters.images-yml-path >> --output-path << parameters.output-path >> --retag $RETAG


          # If the normalized deploy spec exists base64 it and add into base-input-context.json
          if [ -f "<< parameters.output-path >>" ]; then
            echo "Adding normalized deploy.yml to context"
            declare -r normalized_deploy_spec_base64=$(base64 << parameters.output-path >> | tr -d '\n')

            context_content=$(cat \<<EOF
            {
              "name": "normalized_deploy_spec",
              "type": "string",
              "fromLookup": {
                "type": "json",
                "base64": {
                  "value": "${normalized_deploy_spec_base64}",
                  "type": "yaml"
                }
              }
            }
          EOF
          )
            # Insert normalized deploy spec into the inputContext array
            new_base_input_context=$(cat ${janus_context} | jq ".inputContext += [ ${context_content} ]")
            echo "${new_base_input_context}" | jq -r . > ${janus_context}

          else
            echo "No normalized deploy.yml exsts to add to context"
          fi
        name: Normalize deploy.yml script and add to context
    - persist_to_workspace:
        paths:
        - artifacts/Context
        root: /tmp/workspace
  package-lambdas:
    parameters:
      deployment-exports-path:
        default: /tmp/workspace/artifacts/DeploymentExports/dev-deployment-exports.json
        description: Path to a valid deployment-exports json file
        type: string
      prepackage-cmd:
        default: ''
        description: The command to run in each Lambda's source directory before zipping. Use this to install dependencies or build binaries, if necessary. If multiple Lambdas are being packaged and they all need to be handled differently, use the package-lambda command instead.
        type: string
      target-dir:
        default: /tmp/workspace/artifacts/Lambdas/
        description: Path to store packaged lambdas. Must end with a trailing slash
        type: string
    steps:
    - run:
        command: |
          set -eo pipefail
          lambdas=$(cat << parameters.deployment-exports-path >> | jq -rc '. | .lambda_functions[]?')
          if [[ -z $lambdas ]]; then
            echo "There are no Lambdas in the deployment-exports file, skipping"
            exit 0
          fi
          target_dir=<< parameters.target-dir >>
          mkdir -p $target_dir
          # Example deployment exports contents
          # {
          #    "lambda_functions": [
          #        {
          #            "bucket": "dev-spec-validator-lambda-code-bucket",
          #            "function_name": "spec-validator",
          #            "code_path": "./",
          #            "runtime": "python3.7"
          #        }
          # }

          # Check if directory exists and is non-empty
          if [[ -d /tmp/workspace/artifacts/OutputFiles/lambda-functions/ && "$(ls -A /tmp/workspace/artifacts/OutputFiles/lambda-functions/)" ]]; then
            # Move any canned Lambdas that may have been copied into the workspace by stack-formation
            mkdir -p ./lambda-functions
            mv /tmp/workspace/artifacts/OutputFiles/lambda-functions/* ./lambda-functions
          fi
          # Iterate over lambda functions object in deployment exports, if it exists
          cat << parameters.deployment-exports-path >> | jq -rc '. | .lambda_functions[]? | .function_name + " " + .code_path + " " + .runtime' | while read i; do
              # read the json keys into bash variables of the same name
              read function_name code_path runtime < <(echo "$i")
              cd "${code_path}"
              # iam-user-key-manager and es-domain-logging are lambdas that come from stack-formation and don't need to have the prepackage-cmd run on them.
              if [[ $code_path != *"iam-user-key-manager"* && $code_path != *"es-domain-logging"* ]]; then
                echo "Run prepackage command if exists."
                << parameters.prepackage-cmd >>
              fi
              # Could not come up with immmediate elegant solution to support this via param
              zip -x '/*.git*/*' -x '/*.janus/*' -x '/tests/*' -r "${target_dir}${function_name}.zip" .
              # cd back, so we're in the right directory for the next iteration
              cd -
          done
        name: Package lambdas
  package-s3-contents:
    parameters:
      artifacts-target-dir:
        default: /tmp/workspace/artifacts/
        description: Location where artifacts will be published from, usually by the `publish-artifacts` job in this orb
        type: string
      deployment-exports-path:
        default: /tmp/workspace/artifacts/DeploymentExports/dev-deployment-exports.json
        description: Path to a valid deployment-exports json file
        type: string
      get-s3-contents-from-workspace:
        default: false
        description: Whether to look for the artifacts in the repo or the workspace. If the contents are committed, leave this as the default. If the contents are *built* by a previous job, they will be persisted to the workspace by that job, which will be handled by settings this parameter to `true`.
        type: boolean
      s3-contents-source-path:
        default: /tmp/workspace/
        description: Path to prefix for s3 content locations. Only applicable when `get-s3-contents-from-workspace` is set to `true`
        type: string
    steps:
    - run:
        command: |
          # Example deployment exports contents
          # {
          #   "s3_buckets": [
          #     {
          #       "bucket_name": "app",
          #       "contents_path": "./publish/",
          #       "public": true
          #     }
          #   ]
          # }
          # Iterate over s3_buckets object in deployment exports, if it exists
          set -eo pipefail
          # Keep track of where we are
          current_dir=$(pwd)
          cat << parameters.deployment-exports-path >> | jq -rc '. | .s3_buckets[]? | .bucket_name + " " + .contents_path + " " + (.public|tostring)' | while read i; do
              # read the json keys into bash variables of the same name
              read bucket_name contents_path public < <(echo "$i")
              path_prefix=<<# parameters.get-s3-contents-from-workspace >><< parameters.s3-contents-source-path >><</ parameters.get-s3-contents-from-workspace >>
              if [[ ! -d "${path_prefix}${contents_path}" ]]; then
                echo "No contents found to upload for $bucket_name. This is usually fine"
                break
              fi
              if [ $public == 'true' ]; then
                destination_dir="<< parameters.artifacts-target-dir >>PublicAssets"
              else
                destination_dir="<< parameters.artifacts-target-dir >>Assets"
              fi
              mkdir -p "${destination_dir}"
              staging_dir=/tmp/$bucket_name
              mkdir -p "${staging_dir}"
              # need to normalize source path. cd to contents path means we dont' have to worry about whether it contains a trailing slash
              cd "${path_prefix}${contents_path}"
              cp -R ./. "${staging_dir}"
              cd "${staging_dir}"
              zip -r "${bucket_name}.zip" .
              # Be explicit about where are going
              cd "${current_dir}"
              mv "${staging_dir}/${bucket_name}.zip" "${destination_dir}"
          done
        description: Uses DeploymentExports file to learn where to find assets for s3 buckets. Zips contents as <bucket-name>.zip and places it in either Assets or PublicAssets for deployment.
        name: Package for S3
        shell: bash
  post-version-pr-comment:
    description: Post a comment to Github pull request
    parameters:
      bot-token-variable:
        default: GITHUB_TOKEN
        type: env_var_name
      bot-user:
        default: read-automation
        description: Env var for the password to log into the docker registry
        type: string
      janus-version-path:
        default: /tmp/workspace/janus_version
        description: Env var for the user to log into the docker registry
        type: string
      stack-name-path:
        default: /tmp/workspace/stack_name
        description: Name of stack
        type: string
    steps:
    - checkout
    - run:
        command: |-
          PR_NUMBER=`git log -1 --pretty=%s. | sed -n 's/Merge pull request #\([0-9]*\) from.*/\1/p'` GIT_COMMIT=${CIRCLE_SHA1} BUILD_URL=${CIRCLE_BUILD_URL}
          if [ "$PR_NUMBER" == "" ];then
            echo "No pr found; do nothing. If this is a mistake, check if your PR commit message matches 'Merge pull request #\([0-9]*\) from ...'"
            exit 0
          fi
          VERSION=$(cat << parameters.janus-version-path >>) REPO=$(cat << parameters.stack-name-path >>)
          curl -X POST -u "${<< parameters.bot-user >>}":"${<< parameters.bot-token-variable >>}" "https://api.github.com/repos/cambiahealth/${REPO}/issues/${PR_NUMBER}/comments" -d "{\"body\":\"Janus Version Published: ${VERSION}\nCommit: ${GIT_COMMIT}\nBuild: ${BUILD_URL}\"}"
        name: Post comment to Github PR
  stack-review:
    description: To be run against a normalized deploy.yml, which it expects to exist in the workspace at ./NormalizedJanusDeployment.yml by default. Later in the build, and/or during deployment, the signature is used to verify that the stack passed review. On success, writes signature to /<workspace-root>/review.sig
    parameters:
      normalized-deploy-spec-path:
        default: /tmp/workspace/NormalizedJanusDeployment.yml
        description: Path to normalized deploy spec
        type: string
      signature-target-path:
        default: /tmp/workspace/artifacts/review.sig
        description: Location where stack-review signature should be written
        type: string
    steps:
    - run:
        command: |
          HTTP_RESPONSE=$(curl --silent --write-out "HTTP_STATUS:%{http_code}" -X POST  --data-binary  @<< parameters.normalized-deploy-spec-path >> https://stack-review-stack-review-api.tools-prd.janusplatform.io/stack-review/validate)
          HTTP_STATUS=$(echo "$HTTP_RESPONSE" | tr -d '\n' | sed -e 's/.*HTTP_STATUS://')
          HTTP_BODY=$(echo "$HTTP_RESPONSE" | sed -e 's/HTTP_STATUS\:.*//g')
          if [[ $HTTP_STATUS -lt 200 || $HTTP_STATUS -ge 300 ]]; then
            echo $HTTP_BODY | jq
            exit 1
          fi
          echo "Success. Writing signature file"
          mkdir -p $(dirname << parameters.signature-target-path >>)
          echo "$HTTP_BODY" | jq -r .signature | base64 -d > << parameters.signature-target-path >>
        name: Send deploy spec to stack-review API
  stage-ecr-repos:
    description: |
      Writes a file containing the standard janus repositories that should always be available. Used in conjuction with ensure-repos to make sure repositories pushed to by non-stack-build orbs exist.
    parameters:
      stack-name-path:
        default: /tmp/workspace/stack_name
        description: File containing the name of the stack being built
        type: string
      standard-repos-output:
        default: /tmp/workspace/image-files/janus-platform-standard/repos.txt
        description: Where to put output.
        type: string
    steps:
    - run:
        command: |
          set -ux
          declare -r stack_name=$(cat << parameters.stack-name-path >>)
          declare -r post_deploy_repo="${AWS_ECR_ACCOUNT_URL}/temp_janus-stack-tests/${stack_name}"

          mkdir -p $(dirname << parameters.standard-repos-output >>)
          echo ${post_deploy_repo} > << parameters.standard-repos-output >>
        name: Write Standard Repositories File
  validate-deploy-spec:
    description: Sends deploy.yml to spec-validator for schema validation
    parameters:
      spec-path:
        default: /tmp/workspace/deploy.yml
        description: Path to deploy spec to be validated
        type: string
    steps:
    - run:
        command: |
          HTTP_RESPONSE=$(curl --silent --write-out "HTTP_STATUS:%{http_code}" -X POST  -H "content-type: application/yaml" --data-binary @<< parameters.spec-path >> https://spec-validator-main-api.tools-prd.janusplatform.io/main/validate/deploy?version=2)
          HTTP_STATUS=$(echo "$HTTP_RESPONSE" | tr -d '\n' | sed -e 's/.*HTTP_STATUS://')
          HTTP_BODY=$(echo "$HTTP_RESPONSE" | sed -e 's/HTTP_STATUS\:.*//g')
          if [[ $HTTP_STATUS -lt 200 || $HTTP_STATUS -ge 300 ]]; then
            echo "Spec validation failed with status code $HTTP_STATUS"
            echo $HTTP_BODY | jq
            exit 1
          fi
          valid=$(echo $HTTP_BODY | jq '.valid')
          if [[ $valid != 'true' ]]; then
            echo "Spec validation failed with status code $HTTP_STATUS"
            echo $HTTP_BODY | jq
            echo "Ensure you have upgraded deploy.yml to 'format_version: 2', which removes support for 'resoures_I_provision.docker_images', and requires the 'exposed_port' key be set for at least one service's container if there is an ecs_service provisioned. See https://github.com/cambiahealth/spec-validator/blob/master/tests/data/schemas/deploy/v2/valid-configs/provision-service.yml#L13 for an example. This is a breaking change from how things worked in Jenkins builds, where the exposed port could be inferred, but it comes with the advantage of faster builds in CircleCI because jobs that previously had to run serially and wait for the image build can now run almost instantly."
            exit 1
          fi
        name: Validate deploy spec
  write-stack-name:
    description: Write stack name file manually. Useful for infra-stacks
    parameters:
      stack-name:
        description: Name of current stack
        type: string
      stack-name-target-path:
        default: /tmp/workspace/stack_name
        description: Path to write version file
        type: string
    steps:
    - run:
        command: |
          mkdir -p $(dirname << parameters.stack-name-target-path >>)
          echo << parameters.stack-name >> > << parameters.stack-name-target-path >>
        name: Write stack name
description: Common functionality for CI on Janus Platform
examples:
  additional-images:
    description: Example of a stack-build workflow with additional images to push to ECR.
    usage:
      orbs:
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/prep-image-build:
              context: cambia
              docker-context: .
              dockerfile: ./Dockerfile.first
              ecr-repo: build-args-tester/sidecar
              extra-image-tags: test,mock
              name: first-extra-image
              requires:
              - sb/preflight
          - sb/prep-image-build:
              build-args: KEY=value,KEY2=value
              context: cambia
              docker-context: .
              dockerfile: ./Dockerfile.second
              ecr-repo: build-args-tester/mock
              name: second-extra-image
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              context: cambia
              requires:
              - sb/extractor
              - first-extra-image
              - second-extra-image
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
        version: 2
  containerless:
    description: Example of the stack-build workflow for a stack without a docker container
    usage:
      orbs:
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/preflight
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
        version: 2
  gcp:
    description: Example of a simple GCP workflow
    usage:
      orbs:
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight:
              context: cambia
              validate: false
          - sb/ganus-stack-formation:
              context: cambia
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/preflight
              - sb/ganus-stack-formation
        version: 2
  golang-lambda:
    description: Build a golang serverless stack
    usage:
      executors:
        golang:
          docker:
          - image: circleci/golang:1.13.3
      orbs:
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/preflight
          - sb/stack-formation:
              context: cambia
              executor: golang
              lambda-prepackage-cmd: go build
              pre-steps:
              - run: git config --global url."https://${GITHUB_TOKEN}:x-oauth-basic@github.com/".insteadOf "https://github.com/"
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
        version: 2
  images-only:
    description: Example of a pure image repo workflow.
    usage:
      orbs:
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/prep-image-build:
              context: cambia
              docker-context: .
              dockerfile: ./Dockerfile.sidecar
              ecr-repo: my-stack-name/sidecar
              extra-image-tags: sidecar
              name: sidecar-image
              requires:
              - sb/preflight
          - sb/prep-image-build:
              build-args: KEY=value,KEY2=value
              context: cambia
              docker-context: .
              dockerfile: ./Dockerfile.mock
              ecr-repo: my-stack-name/mock
              extra-image-tags: test,mock
              name: mock-image
              requires:
              - sb/preflight
          - sb/image-builder:
              context: cambia
              requires:
              - sidecar-image
              - mock-image
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/image-builder
        version: 2
  java-lambda:
    description: Build a Java serverless stack
    usage:
      orbs:
        java: cambiahealth/janus-java@1
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/preflight
          - sb/stack-formation:
              context: cambia
              executor: java/java11-builder
              lambda-prepackage-cmd: mvn clean package
              pre-steps:
              - java/maven-configure-authentication
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
        version: 2
  java-library:
    description: Build a NodeJS microservice, where the npm install runs in CircleCI using cached dependencies
    usage:
      orbs:
        janus-java: cambiahealth/janus-java@1
      version: 2.1
      workflows:
        build:
          jobs:
          - janus-java/maven-build-java11:
              context: cambia
              filters:
                branches:
                  ignore: master
        build-and-deploy:
          jobs:
          - janus-java/maven-build-java11:
              build_command: mvn clean deploy --batch-mode -U
              context: REPLACEME
              filters:
                branches:
                  only: master
        version: 2
  nodejs-circleci-build:
    description: Build a NodeJS microservice, where the npm install runs in CircleCI using cached dependencies
    usage:
      commands:
        restore_npm_deps:
          description: npm-install job saves node_modules directory after npm install. This command will restore it back to the working directory, which is needed for the docker build
          steps:
          - restore_cache:
              keys:
              - node-deps-v1-prd-{{ .Branch }}-{{ checksum "package.json" }}
      jobs:
        npm-install:
          environment:
            NODE_ENV: production
          executor:
            name: node/default
            tag: '10.16'
          steps:
          - checkout
          - js/configure-npm
          - node/with-cache:
              cache-version: v1-prd
              steps:
              - run: npm install
        npm-test:
          environment:
            NODE_ENV: ci
          executor:
            name: node/default
            tag: '10.16'
          steps:
          - checkout
          - js/configure-npm
          - node/with-cache:
              cache-version: v1-dev
              steps:
              - run: |
                  npm install
                  npm test
      orbs:
        cuke: cambiahealth/cucumber@1
        js: cambiahealth/janus-javascript@0
        node: circleci/node@1.1.6
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - npm-test:
              context: cambia
          - npm-install:
              context: cambia
          - cuke/run-tests:
              checkout: false
              context: cambia
              pre-steps:
              - checkout
              - restore_npm_deps
              requires:
              - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              checkout: false
              context: cambia
              pre-steps:
              - checkout
              - restore_npm_deps
              requires:
              - sb/extractor
              - npm-install
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
              - cuke/run-tests
              - npm-test
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
              - cuke/run-tests
              - npm-test
        version: 2
  nodejs-lambda:
    description: Build a NodeJS serverless stack
    usage:
      orbs:
        js: cambiahealth/janus-javascript@0
        node: circleci/node@1.1.6
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/preflight
          - sb/stack-formation:
              context: cambia
              executor: node/default
              lambda-prepackage-cmd: npm install && npm build
              pre-steps:
              - js/configure-npm
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
        version: 2
  python-lambda:
    description: Build a python serverless stack
    usage:
      orbs:
        python: cambiahealth/janus-python:0
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/preflight
          - sb/stack-formation:
              context: cambia
              lambda-prepackage-cmd: pip install -r requirements.txt --target .
              pre-steps:
              - python/generate-pip-conf
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
        version: 2
  service:
    description: Full example of stack-build workflow with cucumber
    usage:
      orbs:
        cuke: cambiahealth/cucumber@1
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - cuke/run-tests:
              context: cambia
              requires:
              - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              context: cambia
              requires:
              - sb/extractor
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
              - cuke/run-tests
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
              - cuke/run-tests
        version: 2
  service-with-golang:
    description: Full example of stack-build workflow for golang
    usage:
      commands:
        run-docker-build:
          description: Build docker image
          steps:
          - checkout
          - sb/docker-login-jpio
          - aws-ecr/ecr-login
          - run:
              command: |
                echo "export REPO_NAME=REPLACEME" >> ~/.bashrc
                source ~/.bashrc
                echo "REPO_NAME: ${REPO_NAME}"
                aws ecr describe-repositories --region ${AWS_REGION} --repository-names ${REPO_NAME} || \
                aws ecr create-repository --region ${AWS_REGION} --repository-name ${REPO_NAME}
              name: setup repo
          - run:
              command: |
                source ~/.bashrc
                janus_version=$(cat /tmp/workspace/janus_version)
                artifact_tag=${AWS_ECR_ACCOUNT_URL}/<ecr repo>/temp_main:temp_${janus_version}
                docker build -f './Dockerfile' -t "${artifact_tag}" --build-arg 'ARTIFACTORY_API_KEY' --build-arg 'ARTIFACTORY_USER' --build-arg 'ARTIFACTORY_B64' --build-arg 'SSH_PRIVATE_KEY' .
                docker push ${artifact_tag}
              name: Build from dockerfile and push
      executors:
        cached-machine:
          description: |
            CircleCI's Ubuntu-based machine executor VM: https://circleci.com/docs/2.0/executor-types/#using-machine
          machine:
            docker_layer_caching: true
            image: <<parameters.image>>
          parameters:
            image:
              default: ubuntu-1604:201903-01
              type: string
        custom-docker-executor:
          machine:
            docker_layer_caching: true
            image: ubuntu-1604:201903-01
          resource_class: large
      jobs:
        image:
          executor: custom-docker-executor
          steps:
          - run-docker-build
        run-cukes:
          executor: custom-docker-executor
          steps:
          - checkout
          - run:
              command: |
                docker images
                docker version
              name: Docker images list
          - sb/docker-login-jpio
          - aws-ecr/ecr-login
          - run:
              command: |
                source ~/.bashrc
                SSH_PRIVATE_KEY=${SSH_PRIVATE_KEY} docker-compose -f docker-compose-tests.yml up --build -V --abort-on-container-exit
                mkdir -p /tmp/workspace/artifacts/TestReports
                ls -l .
                cp cucumber.* /tmp/workspace/artifacts/TestReports
                ls -l /tmp/workspace/artifacts/TestReports
              name: Run the cuke scenarios
          - persist_to_workspace:
              paths:
              - artifacts/TestReports/cucumber.*
              root: /tmp/workspace/
          - store_artifacts:
              destination: TestReports/cucumber.html
              path: cucumber.html
          - store_artifacts:
              destination: TestReports/cucumber.json
              path: cucumber.json
        test-short:
          docker:
          - image: circleci/golang:1.13.3
          environment:
            GOCACHE: /tmp/go/cache
          steps:
          - add_ssh_keys:
              fingerprints:
              - d8:13:e5:af:57:24:b3:3f:74:8c:02:4a:c4:25:bf:cb
          - checkout
          - restore_cache:
              keys:
              - go-mod-v1-{{ checksum "go.sum" }}
          - restore_cache:
              keys:
              - build-cache-{{ .Branch }}-{{ .Environment.CIRCLE_PREVIOUS_BUILD_NUM }}
          - run:
              command: go test -v -cover -short -timeout=3s ./...
              name: Run unit tests
          - save_cache:
              key: go-mod-v1-{{ checksum "go.sum" }}
              paths:
              - /go/pkg/mod
          - save_cache:
              key: build-cache-{{ .Branch }}-{{ .Environment.CIRCLE_BUILD_NUM }}
              paths:
              - /tmp/go/cache
      orbs:
        aws-ecr: circleci/aws-ecr@6.5.0
        sb: cambiahealth/stack-build@volatile
      version: 2.1
      workflows:
        build_and_deploy_mocks_image:
          jobs:
          - aws-ecr/build-and-push-image:
              checkout: false
              context: REPLACEME
              create-repo: true
              dockerfile: Dockerfile.mocks
              executor: cached-machine
              filters:
                branches:
                  only:
                  - master
              pre-steps:
              - sb/docker-login-jpio
              - checkout
              repo: <ecr repo>/mock
              tag: latest,$CIRCLE_BRANCH,$CIRCLE_BRANCH-$CIRCLE_BUILD_NUM
        janus-pipeline:
          jobs:
          - sb/preflight
          - test-short:
              context: cambia
          - run-cukes:
              context: cambia
              pre-steps:
              - add_ssh_keys:
                  fingerprints:
                  - d8:13:e5:af:57:24:b3:3f:74:8c:02:4a:c4:25:bf:cb
              - run:
                  command: |
                    echo "export SSH_PRIVATE_KEY=\"$(cat ~/.ssh/id_rsa_d813e5af5724b33f748c024ac425bfcb)\"" >> ~/.bashrc
                  name: Set SSH env var
              requires:
              - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - image:
              context: REPLACEME
              pre-steps:
              - add_ssh_keys:
                  fingerprints:
                  - d8:13:e5:af:57:24:b3:3f:74:8c:02:4a:c4:25:bf:cb
              - run:
                  command: |
                    echo "export SSH_PRIVATE_KEY=\"$(cat ~/.ssh/id_rsa_d813e5af5724b33f748c024ac425bfcb)\"" >> ~/.bashrc
                  name: Set SSH env var
              - attach_workspace:
                  at: /tmp/workspace/
              requires:
              - sb/extractor
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/stack-formation:
              context: cambia
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - image
              - run-cukes
              - test-short
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - image
              - run-cukes
              - test-short
        version: 2
  service-with-java:
    description: Full example of stack-build workflow for java11
    usage:
      orbs:
        cuke: cambiahealth/cucumber@1
        janus-java: cambiahealth/janus-java@1
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - janus-java/maven-build-java11:
              context: cambia
          - cuke/run-tests:
              checkout: false
              context: cambia
              pre-steps:
              - checkout
              - attach_workspace:
                  at: /tmp/workspace
              - run: cp -R /tmp/workspace/target/ .
              requires:
              - sb/preflight
              - janus-java/maven-build-java11
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              checkout: false
              context: cambia
              pre-steps:
              - checkout
              - attach_workspace:
                  at: /tmp/workspace
              - run: cp -R /tmp/workspace/target/ .
              requires:
              - sb/extractor
              - janus-java/maven-build-java11
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
              - cuke/run-tests
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
              - cuke/run-tests
        version: 2
  service-with-node:
    description: |
      Build a NodeJS microservice, where the npm install happens in the Dockerfile.
      This requires the following line in your Dockerfile(s)
      COPY --chown=node:node .npmrc /home/node/.npmrc
    usage:
      orbs:
        cuke: cambiahealth/cucumber@1
        js: cambiahealth/janus-javascript@0
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - cuke/run-tests:
              checkout: false
              context: cambia
              pre-steps:
              - checkout
              - js/configure-npm:
                  target: .npmrc
              requires:
              - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              checkout: false
              context: cambia
              pre-steps:
              - checkout
              - js/configure-npm:
                  target: .npmrc
              requires:
              - sb/extractor
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
              - cuke/run-tests
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
              - cuke/run-tests
        version: 2
  service-with-python:
    description: Full example of stack-build workflow for python
    usage:
      orbs:
        cuke: cambiahealth/cucumber@1
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - cuke/run-tests:
              context: cambia
              requires:
              - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              context: cambia
              requires:
              - sb/extractor
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
              - cuke/run-tests
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
              - cuke/run-tests
        version: 2
  service-without-cucumber:
    description: Example of a standard stack-build workflow (without cucumber)
    usage:
      orbs:
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              context: cambia
              requires:
              - sb/extractor
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
        version: 2
  standard:
    description: Full example of stack-build workflow with cucumber
    usage:
      orbs:
        cuke: cambiahealth/cucumber@1
        sb: cambiahealth/stack-build@1
      version: 2.1
      workflows:
        janus-pipeline:
          jobs:
          - sb/preflight
          - cuke/run-tests:
              context: cambia
              requires:
              - sb/preflight
          - sb/extractor:
              context: cambia
              requires:
              - sb/preflight
              retag-external-images: false
          - sb/normalize:
              context: cambia
              requires:
              - sb/extractor
          - sb/image-builder:
              context: cambia
              requires:
              - sb/extractor
          - sb/stack-formation:
              context: cambia
              requires:
              - sb/normalize
          - sb/stack-review:
              requires:
              - sb/normalize
          - sb/publish-images:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/image-builder
              - sb/stack-review
              - cuke/run-tests
          - sb/publish-artifacts:
              context: REPLACEME
              filters:
                branches:
                  only:
                  - master
              requires:
              - sb/stack-formation
              - sb/stack-review
              - sb/image-builder
              - cuke/run-tests
        version: 2
executors:
  default:
    docker:
    - image: circleci/python:3
  ganus-stack-formation:
    docker:
    - auth:
        password: $ARTIFACTORY_API_KEY
        username: $ARTIFACTORY_USER
      image: docker-registry.janusplatform.io/janus/ganus-stack-formation:<< parameters.tag >>
    parameters:
      tag:
        default: master
        type: string
  node-lambda-packager:
    docker:
    - auth:
        password: $ARTIFACTORY_API_KEY
        username: $ARTIFACTORY_USER
      image: docker-registry.janusplatform.io/janus/node-lambda-packager:<< parameters.tag >>
    parameters:
      tag:
        default: circleci
        type: string
  python-executor:
    docker:
    - auth:
        password: $ARTIFACTORY_API_KEY
        username: $ARTIFACTORY_USER
      image: docker-registry.janusplatform.io/janus/stack-build-python-executor:<< parameters.tag >>
    parameters:
      tag:
        default: '1'
        type: string
  stack-formation:
    docker:
    - auth:
        password: $ARTIFACTORY_API_KEY
        username: $ARTIFACTORY_USER
      environment:
        GIT_BRANCH: $CIRCLE_BRANCH
        GIT_COMMIT: $CIRCLE_SHA1
      image: docker-registry.janusplatform.io/janus/stack-formation:<< parameters.tag >>
    parameters:
      tag:
        default: master
        type: string
jobs:
  extractor:
    description: Parse deploy.yml to images.yml
    executor:
      name: python-executor
      tag: <<parameters.tag>>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      container-target-dir:
        default: containers/
        description: Subdirectory for extractor output derived from deploy-spec.
        type: string
      deploy-spec-path:
        default: deploy.yml
        description: Path to deploy.yml
        type: string
      retag-external-images:
        default: true
        description: |
          Boolean for whether to retag external images. Default is true. See link below for details. https://cambiahealth.atlassian.net/wiki/spaces/CCSE/pages/744836/CircleCI+-+Config.yml#CircleCI-Config.yml-ConsumedImages
        type: boolean
      stack-name-path:
        default: stack_name
        description: File containing the name of the stack being built
        type: string
      tag:
        default: '1'
        description: The tag of the image builder utility (not applied to images the orb builds)
        type: string
      version-path:
        default: janus_version
        description: File containing the version of the stack being built
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - run:
        command: |
          set -x
          stack_name=$(cat << parameters.workspace-root >><< parameters.stack-name-path >>)
          janus_version=$(cat << parameters.workspace-root >><< parameters.version-path >>)
          mkdir -p "<< parameters.workspace-root >>image-files/<< parameters.container-target-dir >>"
          extractor.py --janusconfig << parameters.workspace-root >><< parameters.deploy-spec-path >> \
            --version $janus_version \
            --stack-name $stack_name \
            --output-dir "<< parameters.workspace-root >>image-files/<< parameters.container-target-dir >>" \
            --retag << parameters.retag-external-images >>
        name: Parse deploy.yml to generate images.yml
    - run:
        command: |
          echo "RETAG=<< parameters.retag-external-images >>" >> << parameters.workspace-root >>env_var
        name: Save retag-external-images boolean value to env_var
    - persist_to_workspace:
        paths:
        - image-files/<< parameters.container-target-dir >>images.yml
        - image-files/<< parameters.container-target-dir >>timestamp_images_output.yml
        - image-files/<< parameters.container-target-dir >>final_tags_output.json
        - image-files/<< parameters.container-target-dir >>repos.txt
        - image-files/<< parameters.container-target-dir >>final_repos.txt
        - env_var
        root: << parameters.workspace-root >>
    - run:
        command: |
          mkdir extractor-artifacts
          cp "image-files/<< parameters.container-target-dir >>images.yml" extractor-artifacts/
          cp "image-files/<< parameters.container-target-dir >>timestamp_images_output.yml" extractor-artifacts/
          cp "image-files/<< parameters.container-target-dir >>final_tags_output.json" extractor-artifacts/
          cp "image-files/<< parameters.container-target-dir >>repos.txt" extractor-artifacts/
          cp "image-files/<< parameters.container-target-dir >>final_repos.txt" extractor-artifacts/
        name: Copy intermediate artifacts for inspection
        working_directory: << parameters.workspace-root >>
    - store_artifacts:
        destination: extractor
        path: << parameters.workspace-root >>/extractor-artifacts/
  ganus-stack-formation:
    executor: ganus-stack-formation
    parameters:
      checkout:
        default: true
        description: |
          Boolean for whether or not to checkout code. Default is true.
        type: boolean
    steps:
    - when:
        condition: << parameters.checkout >>
        steps:
        - checkout
    - run:
        command: python -u src/main.py build -i ~/project -o /tmp/artifacts/
        name: Form Janus Google stack
        working_directory: /usr/app
    - persist_to_workspace:
        paths:
        - artifacts/
        root: /tmp
  generate-janus-context:
    description: Create the Context directory and populate with per environment values
    executor:
      name: python-executor
      tag: <<parameters.tag>>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      aws-region:
        default: us-west-2
        description: Target aws region
        type: string
      deploy-spec-path:
        default: deploy.yml
        description: Path to deploy.yml
        type: string
      output-dir:
        default: artifacts/Context
        description: Path to Context
        type: string
      stack-name-path:
        default: stack_name
        description: File containing the name of the stack being built
        type: string
      tag:
        default: '1'
        description: The tag of the image builder utility (not applied to images the orb builds)
        type: string
      version-path:
        default: janus_version
        description: File containing the version of the stack being built
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - generate-janus-context:
        aws-region: << parameters.aws-region >>
        deploy-spec-path: << parameters.workspace-root >><< parameters.deploy-spec-path >>
        output-dir: << parameters.workspace-root >><< parameters.output-dir >>
        stack-name-path: << parameters.workspace-root >><< parameters.stack-name-path >>
        version-path: << parameters.workspace-root >><< parameters.version-path >>
    - persist_to_workspace:
        paths:
        - << parameters.output-dir >>
        root: << parameters.workspace-root >>
    - store_artifacts:
        destination: artifacts
        path: << parameters.workspace-root >><< parameters.output-dir >>
  generate-version:
    description: Just generates and persists a version file. Useful for infrastacks or other workflows that don't require the full preflight job
    executor: default
    parameters:
      version-target-path:
        default: janus_version
        description: Path to write version file, relative to workspace root
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - generate-version:
        version-target-path: << parameters.workspace-root >><< parameters.version-target-path >>
    - persist_to_workspace:
        paths:
        - << parameters.version-target-path >>
        root: << parameters.workspace-root >>
  image-builder:
    description: Build docker images in Janus build pipeline format
    executor:
      name: python-executor
      tag: <<parameters.tag>>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      aws-access-key-id:
        default: AWS_ACCESS_KEY_ID
        description: |
          AWS access key id for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_ACCESS_KEY.
        type: env_var_name
      aws-secret-access-key:
        default: AWS_SECRET_ACCESS_KEY
        description: |
          AWS secret key for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_SECRET_ACCESS_KEY.
        type: env_var_name
      build-args:
        default: ''
        description: Build time args to be passed into docker image
        type: string
      checkout:
        default: true
        description: |
          Boolean for whether or not to checkout code. Default is true.
        type: boolean
      ecr-access-policy-parameter-name:
        default: /janus/build/ecr/cross-account-access-policy
        description: The name of the param store parameter that contains ECR access policy
        type: string
      ecr-lifecycle-policy-parameter-name:
        default: /janus/build/ecr/lifecycle-policy
        description: The name of the param store parameter that contains ECR lifecycle policy
        type: string
      profile-name:
        default: default
        description: AWS profile name to be configured.
        type: string
      region:
        default: AWS_REGION
        description: |
          Name of env var storing your AWS region information, defaults to AWS_REGION
        type: env_var_name
      stack-name-path:
        default: stack_name
        description: File containing the name of the stack being built
        type: string
      tag:
        default: '1'
        description: The tag of the image builder utility (not applied to images the orb builds)
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.checkout>>
        steps:
        - checkout
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - run:
        command: |
          echo "Running script to generate the bash script that builds and pushes temporary docker images. See code at https://github.com/cambiahealth/stack-build-python-executor/blob/master/bin/prep_build_script.py"
          export build_arg="--buildargs << parameters.build-args >>"
          # Only add buildargs flag if parameters.build-args contains something, i.e. if the value of $build_arg has more characters than "--buildarg " (12).
          if [[ ${#build_arg} -gt 12 ]]; then
              prep_build_script.py $build_arg --imagesdir << parameters.workspace-root >>image-files --output "<< parameters.workspace-root >>image-files/build-images.sh"
          else
              prep_build_script.py --imagesdir << parameters.workspace-root >>image-files --output "<< parameters.workspace-root >>image-files/build-images.sh"
          fi
          cat << parameters.workspace-root >>image-files/build-images.sh
        name: Prepare build-tag-push script
    - store_artifacts:
        destination: image-builder
        path: << parameters.workspace-root >>image-files/build-images.sh
    - setup_remote_docker:
        docker_layer_caching: true
    - aws-cli/configure:
        aws-access-key-id: <<parameters.aws-access-key-id>>
        aws-region: <<parameters.region>>
        aws-secret-access-key: <<parameters.aws-secret-access-key>>
        profile-name: <<parameters.profile-name>>
    - aws-ecr/ecr-login
    - docker-login-jpio
    - stage-ecr-repos:
        stack-name-path: << parameters.workspace-root >><< parameters.stack-name-path >>
    - ensure-repos
    - run:
        command: bash -evo pipefail << parameters.workspace-root >>image-files/build-images.sh
        name: Execute build-tag-push script
    - run:
        command: |
          mkdir image-builder-artifacts
          cp image-files/build-images.sh image-builder-artifacts/
        name: Copy intermediate artifacts for inspection
        working_directory: << parameters.workspace-root >>
    - store_artifacts:
        destination: image-builder
        path: << parameters.workspace-root >>/image-builder-artifacts/
  list-workspace:
    description: |
      Files in a workspace cannot be seen through the UI or when SSH'd into a job.  This job can
      be used to list the contents of the workspace which is useful when adding new artifacts to the
      workspace.
    executor: default
    steps:
    - attach_workspace:
        at: .
    - run:
        command: |
          find . -print
        name: List workspace
  normalize:
    description: Transform deploy.yml to NormalizedJanusDeployment.yml
    executor:
      name: python-executor
      tag: <<parameters.tag>>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      deploy-spec-path:
        default: deploy.yml
        description: Path to deploy.yml
        type: string
      images-yml-path:
        default: image-files/containers/timestamp_images_output.yml
        description: Path to YML file of images to be consumed
        type: string
      output-path:
        default: NormalizedJanusDeployment.yml
        description: Path to normalized deploy.yml
        type: string
      stack-name-path:
        default: stack_name
        description: File containing the name of the stack being built
        type: string
      tag:
        default: '1'
        description: The tag of the image builder utility (not applied to images the orb builds)
        type: string
      version-path:
        default: janus_version
        description: File containing the version of the stack being built
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - normalize-deploy-spec:
        deploy-spec-path: << parameters.workspace-root >><< parameters.deploy-spec-path >>
        images-yml-path: << parameters.workspace-root >><< parameters.images-yml-path >>
        output-path: << parameters.workspace-root >><< parameters.output-path >>
        stack-name-path: << parameters.workspace-root >><< parameters.stack-name-path >>
        version-path: << parameters.workspace-root >><< parameters.version-path >>
    - persist_to_workspace:
        paths:
        - << parameters.output-path >>
        root: << parameters.workspace-root >>
    - run:
        command: |
          mkdir normalize-artifacts
          cp << parameters.output-path >> normalize-artifacts/
        name: Copy intermediate artifacts for inspection
        working_directory: << parameters.workspace-root >>
    - store_artifacts:
        destination: normalize
        path: << parameters.workspace-root >>/normalize-artifacts/
  preflight:
    description: Run a few checks to catch some errors early, and do some minor workspace modifications for later steps
    executor: default
    parameters:
      aws-region:
        default: us-west-2
        description: Target aws region
        type: string
      checkout:
        default: true
        description: |
          Boolean for whether or not to checkout code. Default is true.
        type: boolean
      deploy-spec-target-path:
        default: deploy.yml
        description: Path to save found deploy spec
        type: string
      janus-context-output-dir:
        default: artifacts/Context
        description: Path to write Janus context file
        type: string
      stack-name-target-path:
        default: stack_name
        description: Path to write stack-name file
        type: string
      validate:
        default: true
        description: |
          Whether to POST to the spec-validator endpoint with the deployment spec.
        type: boolean
      version-target-path:
        default: janus_version
        description: Path to write version file
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.checkout>>
        steps:
        - checkout
    - find-and-copy-deploy-spec:
        deploy-spec-target-path: << parameters.workspace-root >><< parameters.deploy-spec-target-path >>
    - when:
        condition: <<parameters.validate>>
        steps:
        - validate-deploy-spec:
            spec-path: << parameters.workspace-root >><< parameters.deploy-spec-target-path >>
    - get-stack-name:
        deploy-spec-path: << parameters.workspace-root >><< parameters.deploy-spec-target-path >>
        stack-name-target-path: << parameters.workspace-root >><< parameters.stack-name-target-path >>
    - generate-version:
        version-target-path: << parameters.workspace-root >><< parameters.version-target-path >>
    - generate-janus-context:
        aws-region: << parameters.workspace-root >><< parameters.aws-region >>
        deploy-spec-path: << parameters.workspace-root >><< parameters.deploy-spec-target-path >>
        output-dir: << parameters.workspace-root >><< parameters.janus-context-output-dir >>
        stack-name-path: << parameters.workspace-root >><< parameters.stack-name-target-path >>
        version-path: << parameters.workspace-root >><< parameters.version-target-path >>
    - persist_to_workspace:
        paths:
        - << parameters.deploy-spec-target-path >>
        - << parameters.stack-name-target-path >>
        - << parameters.version-target-path >>
        - << parameters.janus-context-output-dir >>
        root: << parameters.workspace-root >>
    - store_artifacts:
        destination: << parameters.version-target-path >>
        path: << parameters.workspace-root >><< parameters.version-target-path >>
  prep-image-build:
    description: Parse deploy.yml to images.yml
    executor:
      name: python-executor
      tag: <<parameters.tag>>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      aws-access-key-id:
        default: AWS_ACCESS_KEY_ID
        description: |
          AWS access key id for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_ACCESS_KEY.
        type: env_var_name
      aws-secret-access-key:
        default: AWS_SECRET_ACCESS_KEY
        description: |
          AWS secret key for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_SECRET_ACCESS_KEY.
        type: env_var_name
      build-args:
        default: ''
        description: Build time args to be passed into docker image. Will override those passed to image-builder.
        type: string
      docker-context:
        default: .
        description: null
        type: string
      dockerfile:
        default: ./Dockerfile
        description: null
        type: string
      ecr-repo:
        default: side
        description: Name of ECR repo to store image. Must conform to a pattern supported by your context.
        type: string
      extra-image-tags:
        default: ''
        description: Extra tags to be applied to image in ECR. The current Janus version (YYYYMMDD_HHmmSS) and `latest` are always applied
        type: string
      profile-name:
        default: default
        description: AWS profile name to be configured.
        type: string
      region:
        default: AWS_REGION
        description: |
          Name of env var storing your AWS region information, defaults to AWS_REGION
        type: env_var_name
      stack-name-path:
        default: stack_name
        description: File containing the name of the stack being built
        type: string
      tag:
        default: '1'
        description: The tag of the image builder utility (not applied to images the orb builds)
        type: string
      version-path:
        default: janus_version
        description: File containing the version of the stack being built
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - run:
        command: |
          set -x
          stack_name=$(cat << parameters.workspace-root >><< parameters.stack-name-path >>)
          janus_version=$(cat << parameters.workspace-root >><< parameters.version-path >>)
          dockerfile="<< parameters.dockerfile >>"
          docker_context="<< parameters.docker-context >>"
          ecr_repo="<< parameters.ecr-repo >>"
          registry="774580802320.dkr.ecr.us-west-2.amazonaws.com"
          mkdir -p "<< parameters.workspace-root >>image-files/<< parameters.ecr-repo >>"
          imagefile="<< parameters.workspace-root >>image-files/<< parameters.ecr-repo >>/images.yml"
          build_args="<< parameters.build-args >>"
          extra_tags="<< parameters.extra-image-tags >>"

          # Create images.yml file
          cat >>"${imagefile}" \<<EOF
          - dockerfile: ${dockerfile}
            context: ${docker_context}
            build-args: "${build_args}"
            tags:
              - ${registry}/temp_${ecr_repo}:temp_${janus_version}
          EOF
          # Add any extra image tags to images.yml
          if [[ -n $extra_tags ]]; then
            IFS="," read -r -a repo_tags \<<< "<< parameters.extra-image-tags >>"
            for repo_tag in "${repo_tags[@]}"
            do
              cat >> tags_file\<<EOF
              - ${registry}/temp_${ecr_repo}:${repo_tag}
          EOF
            done
            cat tags_file >>"${imagefile}"
          fi

          # Create final_tags_output file
          taglist="<< parameters.workspace-root >>image-files/${ecr_repo}/final_tags_output.json"
          cat >"${taglist}"\<<EOF
          [
              {
                  "old": "${registry}/temp_${ecr_repo}:temp_${janus_version}",
                  "new": [
                      "${registry}/${ecr_repo}:${janus_version}",
          EOF
          # Add any extra tags
          if [[ -n $extra_tags ]]; then
            IFS="," read -r -a repo_tags \<<< "<< parameters.extra-image-tags >>"
            for repo_tag in "${repo_tags[@]}"
            do
              cat >> "${taglist}"\<<EOF
                      "${registry}/${ecr_repo}:${repo_tag}",
          EOF
            done
          fi
          # Add one more tag and closing brackets(easier to add any extra-tags beforehand because json & commas)
          cat >>"${taglist}"\<<EOF
                      "${registry}/${ecr_repo}:latest"
                  ]
              }
          ]
          EOF
          echo << parameters.ecr-repo >> > "<< parameters.workspace-root >>image-files/<< parameters.ecr-repo >>/final_repos.txt"
        name: Generate image and tag files for docker image
    - aws-cli/configure:
        aws-access-key-id: <<parameters.aws-access-key-id>>
        aws-region: <<parameters.region>>
        aws-secret-access-key: <<parameters.aws-secret-access-key>>
        profile-name: <<parameters.profile-name>>
    - ensure-repos:
        repo: temp_<< parameters.ecr-repo >>
    - persist_to_workspace:
        paths:
        - image-files/<< parameters.ecr-repo >>/images.yml
        - image-files/<< parameters.ecr-repo >>/final_tags_output.json
        - image-files/<< parameters.ecr-repo >>/final_repos.txt
        root: << parameters.workspace-root >>
    - run:
        command: |
          [ -d extractor-artifacts ] || mkdir -p "<< parameters.ecr-repo >>-artifacts"
          cp "image-files/<< parameters.ecr-repo >>/images.yml" "<< parameters.ecr-repo >>-artifacts/"
          cp "image-files/<< parameters.ecr-repo >>/final_tags_output.json" "<< parameters.ecr-repo >>-artifacts/"
          cp "image-files/<< parameters.ecr-repo >>/final_repos.txt" "<< parameters.ecr-repo >>-artifacts/"
        name: Copy intermediate artifacts for inspection
        working_directory: << parameters.workspace-root >>
    - store_artifacts:
        destination: << parameters.ecr-repo >>
        path: << parameters.workspace-root >>/<< parameters.ecr-repo >>-artifacts/
  publish-artifacts:
    description: Upload stack artifacts to artifactory
    executor:
      name: artifactory/default
    parameters:
      artifacts-dir:
        default: artifacts/
        description: Directory containing the artifacts to be published. Must contain a trailing slash
        type: string
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      post-version-pr-comment:
        default: false
        description: |
          Boolean for whether or not to post comment with janus version to PR. Default is false.
        type: boolean
      repository:
        default: janus-stacks
        description: Repository to publish artifacts to
        type: string
      stack-name-path:
        default: stack_name
        description: File containing the name of the stack being built
        type: string
      version-path:
        default: janus_version
        description: File containing the version of the stack being built
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - artifactory/install
    - artifactory/configure
    - run:
        command: |
          # If the janus_version file or stack-name file does not exist or is empty
          # we cannot build the target path correctly
          # Use `-s` to check if the file exists and is not empty
          if [ ! -s << parameters.workspace-root >><< parameters.version-path >> ]; then
            echo "The file '<< parameters.workspace-root >><< parameters.version-path >>' does not exist or is empty. Without that file we do not know where to publish the stack artifacts so we are exiting."
            exit 1
          fi
          if [ ! -s << parameters.workspace-root >><< parameters.stack-name-path >> ]; then
            echo "The file '<< parameters.workspace-root >><< parameters.stack-name-path >>' does not exist or is empty. Without that file we do not know where to publish the stack artifacts so we are exiting."
            exit 1
          fi

          stack_name=$(cat << parameters.workspace-root >><< parameters.stack-name-path >>)
          janus_version=$(cat << parameters.workspace-root >><< parameters.version-path >>)
          # This spec file is defines what to upload to where.  The variables are replaced during the
          # actual execution of the artifactory/upload job.
          cd << parameters.workspace-root >><< parameters.artifacts-dir >>
          echo "Uploading"
          set -eo pipefail
          path="<< parameters.repository >>/${stack_name}/${janus_version}"
          properties="GIT_COMMIT=${CIRCLE_SHA1};BUILD_URL=${CIRCLE_BUILD_URL};GIT_URL=${CIRCLE_REPOSITORY_URL};GIT_BRANCH=${CIRCLE_BRANCH}"
          results=$(jfrog rt upload ./ "${path}/" \
            --build-name=$CIRCLE_PROJECT_REPONAME \
            --build-number=$CIRCLE_BUILD_NUM \
            --props=$properties \
            --recursive=true \
            --flat=false \
            --include-dirs=true)
          echo "Results of upload: $results"
          echo "Parsing success and failure count"
          read successes failures < <(echo $results | jq -r '.totals.success, .totals.failure')
          if [[ $successes -eq 0 || $failures -gt 0 ]]; then
            echo "Error uploading artifacts"
            exit 1
          fi
          # Above command only sets properties on files, not directories
          # Set props on directories to support artifactory python library's branch deployment method, and maybe other things
          echo "Setting properties on directories"
          jfrog rt set-props --include-dirs=true --recursive=true $path $properties
          echo "Published artifacts for JANUS_STACK_VERSION: $janus_version"
          echo "'Build' phase is now complete. Deployment of these artifacts is handled by stack-stage and stack-deploy. See the 'Deploy' section of https://confluence.healthsparq.net/display/JANUS/How+to+watch%2C+debug%2C+and+promote+your+build for more details"
        description: Uploads CF templates, deployment exports, context file(s) and test reports to Artifactory
        name: Publish artifacts
    - when:
        condition: <<parameters.post-version-pr-comment>>
        steps:
        - post-version-pr-comment:
            janus-version-path: << parameters.workspace-root >><< parameters.version-path >>
            stack-name-path: << parameters.workspace-root >><< parameters.stack-name-path >>
  publish-images:
    description: Push final, long-lived docker image tags. Uses the output of image-extractor as input
    executor:
      name: python-executor
      tag: <<parameters.tag>>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      aws-access-key-id:
        default: AWS_ACCESS_KEY_ID
        description: |
          AWS access key id for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_ACCESS_KEY.
        type: env_var_name
      aws-secret-access-key:
        default: AWS_SECRET_ACCESS_KEY
        description: |
          AWS secret key for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_SECRET_ACCESS_KEY.
        type: env_var_name
      post-version-pr-comment:
        default: true
        description: |
          Boolean for whether or not to post comment with janus version to PR. Default is true.
        type: boolean
      profile-name:
        default: default
        description: AWS profile name to be configured.
        type: string
      region:
        default: AWS_REGION
        description: |
          Name of env var storing your AWS region information, defaults to AWS_REGION
        type: env_var_name
      stack-name-path:
        default: stack_name
        description: Path to stack-name file
        type: string
      tag:
        default: '1'
        description: The tag of the image builder utility (not applied to images the orb builds)
        type: string
      tag-list:
        default: final_tags_output.json
        description: Path to retagger output from image-extractor
        type: string
      version-path:
        default: janus_version
        description: Path to version file
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - aws-cli/configure:
        aws-access-key-id: <<parameters.aws-access-key-id>>
        aws-region: <<parameters.region>>
        aws-secret-access-key: <<parameters.aws-secret-access-key>>
        profile-name: <<parameters.profile-name>>
    - ensure-repos:
        input-file-name: final_repos.txt
    - setup_remote_docker:
        docker_layer_caching: true
    - aws-ecr/ecr-login
    - run:
        command: "#!/bin/bash\ntag_list_files=$(find \"<< parameters.workspace-root >>image-files/\" -name \"<< parameters.tag-list >>\")\n# Example input:\n# ```\n# [\n#   {\n#     \"old\": \"docker-registry/image:temp-tag\",\n#     \"new\": [\n#       \"docker-registry/image:new-tag-1\", \n#       \"docker-registry/image:new-tag-2\"\n#     ]\n#   }\n# ]\n# ```\n#\nfor tag_list_file in $tag_list_files; do\n    # Transform yaml file into lines in the format `<old-tag>;<new-tag-1>,<new-tag-2>`\n    tag_list=$(cat $tag_list_file | jq -r '. | map({old: .old, new: (.new | join(\",\"))}) | map(\"\\(.old);\\(.new)\") | .[]')\n    for tag_line in $tag_list; do\n        # old tag (temp tag) is the portion before the ';'\n        temp_tag=$(echo \"$tag_line\" | cut -d\";\" -f1)\n        # new tags are comma separated, the portion after the ';'\n        new_tags_string=$(echo \"$tag_line\" | cut -d\";\" -f2)\n        set -f # avoid globbing (expansion of *).\n        # split the comma separated tags into a bash array\n        new_tags=(${new_tags_string//,/ })\n        for i in \"${!new_tags[@]}\"\n        do\n            new_tag=${new_tags[i]}\n            set -x\n            docker pull $temp_tag\n            docker tag $temp_tag $new_tag\n            docker push $new_tag\n            set +x\n        done\n    done\ndone\n"
        name: Publish to ECR
    - when:
        condition: <<parameters.post-version-pr-comment>>
        steps:
        - post-version-pr-comment:
            janus-version-path: << parameters.workspace-root >><< parameters.version-path >>
            stack-name-path: << parameters.workspace-root >><< parameters.stack-name-path >>
  stack-formation:
    description: Build stack specific cloud formation templates
    executor: << parameters.executor >>
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      checkout:
        default: true
        description: |
          Boolean for whether or not to checkout code. Default is true.
        type: boolean
      deployment-exports-path:
        default: DeploymentExports/dev-deployment-exports.json
        description: Path (relative to output-dir) to a valid deployment-exports json file
        type: string
      executor:
        default: stack-formation
        description: 'Executor to run stack-formation commands with. Must include curl, bash, jq and zip, as well as language-specific Lambda packaging requirements (if any), e.g. to package a Python Lambda with dependencies, the following may be required: git, python, pip, openssh. The default should be fine for Lambdas that only require zipping up'
        type: executor
      form-with-lambda:
        default: true
        description: |
          Use the lambda version of stack-formation over the docker image. NOTE BUILDS BUILT VIA DOCKER CANT MOVE PAST DEV. THE LAMBDA MUST BE USED FOR BUILDS GOING TO PROD
        type: boolean
      get-s3-contents-from-workspace:
        default: false
        description: Whether to look for the artifacts in the repo or the workspace. If the contents are committed, leave this as the default. If the contents are *built* by a previous job, they will be persisted to the workspace by that job, which will be handled by settings this parameter to `true`.
        type: boolean
      lambda-prepackage-cmd:
        default: ''
        description: The command to run in each Lambda's source directory before zipping. Use this to install dependencies or build binaries, if necessary.
        type: string
      lambda-target-dir:
        default: artifacts/Lambdas/
        description: Target directory (relative to workspace-root) for packaged Lambdas. Needs a trailing slash
        type: string
      normalized-deploy-spec-path:
        default: NormalizedJanusDeployment.yml
        description: Path to normalized deploy.yml
        type: string
      output-dir:
        default: artifacts/
        description: Target path (relative to workspace-root) for generated CloudFormation templates. Needs a trailing slash
        type: string
      package-lambdas:
        default: true
        description: Whether to package Lambdas into zips for deployment. Default of `true` is fine if there are no Lambdas
        type: boolean
      package-s3-contents:
        default: true
        description: Whether to package S3 contents into zips for deployment. Default of `true` is fine if there are no contents to publish
        type: boolean
      s3-contents-source-path:
        default: /tmp/workspace/
        description: Path to prefix for s3 content locations. Only applicable when `get-s3-contents-from-workspace` is set to `true`
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.checkout>>
        steps:
        - checkout
    - attach_workspace:
        at: << parameters.workspace-root >>
    - unless:
        condition: <<parameters.form-with-lambda>>
        steps:
        - run:
            command: cd /usr/src/app && python3 ./src/generate.py --janusconfig << parameters.workspace-root >><< parameters.normalized-deploy-spec-path >> --output-dir << parameters.workspace-root >><< parameters.output-dir >> --env-dir /usr/src/app/environment-definitions --no-json
            name: Build with stack-formation Docker Image
    - when:
        condition: <<parameters.form-with-lambda>>
        steps:
          form-stack:
            normalized-deploy-spec-path: << parameters.workspace-root >><< parameters.normalized-deploy-spec-path >>
            output-dir: << parameters.workspace-root >><< parameters.output-dir >>
    - when:
        condition: << parameters.package-lambdas >>
        steps:
        - package-lambdas:
            deployment-exports-path: << parameters.workspace-root >><< parameters.output-dir >><< parameters.deployment-exports-path >>
            prepackage-cmd: << parameters.lambda-prepackage-cmd >>
            target-dir: << parameters.workspace-root >><< parameters.output-dir >>Lambdas/
    - when:
        condition: << parameters.package-s3-contents >>
        steps:
        - package-s3-contents:
            artifacts-target-dir: << parameters.workspace-root >><< parameters.output-dir >>
            deployment-exports-path: << parameters.workspace-root >><< parameters.output-dir >><< parameters.deployment-exports-path >>
            get-s3-contents-from-workspace: << parameters.get-s3-contents-from-workspace >>
            s3-contents-source-path: << parameters.s3-contents-source-path >>
    - persist_to_workspace:
        paths:
        - << parameters.output-dir >>
        root: << parameters.workspace-root >>
    - store_artifacts:
        destination: artifacts
        path: << parameters.workspace-root >><< parameters.output-dir >>
  stack-review:
    description: To be run against a normalized deploy.yml, which it expects to exist in the workspace at ./NormalizedJanusDeployment.yml by default. Later in the build, and/or during deployment, the signature is used to verify that the stack passed review. On success, writes signature to /<workspace-root>/review.sig
    executor: default
    parameters:
      attach-workspace:
        default: true
        description: |
          Boolean for whether or not to attach to an existing workspace. Default is true.
        type: boolean
      normalized-deploy-spec-path:
        default: NormalizedJanusDeployment.yml
        description: Path to normalized deploy spec
        type: string
      signature-target-path:
        default: artifacts/review.sig
        description: Location where stack-review signature should be written
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - when:
        condition: <<parameters.attach-workspace>>
        steps:
        - attach_workspace:
            at: <<parameters.workspace-root>>
    - stack-review:
        normalized-deploy-spec-path: << parameters.workspace-root >><< parameters.normalized-deploy-spec-path >>
        signature-target-path: << parameters.workspace-root >><< parameters.signature-target-path >>
    - persist_to_workspace:
        paths:
        - << parameters.signature-target-path >>
        root: << parameters.workspace-root >>
  write-stack-name:
    description: Just writes a stack-name file. Useful for infra-stacks or other workflows that don't require the full preflight job or don't have a deploy.yml
    executor: default
    parameters:
      stack-name:
        description: Name of current stack
        type: string
      stack-name-target-path:
        default: stack_name
        description: Path to write version file
        type: string
      workspace-root:
        default: /tmp/workspace/
        description: Directory of persisted artifacts. Must end with a trailing slash
        type: string
    steps:
    - write-stack-name:
        stack-name: << parameters.stack-name >>
        stack-name-target-path: << parameters.workspace-root >><< parameters.stack-name-target-path >>
    - persist_to_workspace:
        paths:
        - << parameters.stack-name-target-path >>
        root: << parameters.workspace-root >>
orbs:
  artifactory:
    commands:
      build-integration:
        description: |
          Publish build information to JFrog Artifactory with `jfrog rt bp`
        parameters:
          build-name:
            default: ${CIRCLE_PROJECT_REPONAME}
            description: |
              Artifactory build name, defaults to the value of $CIRCLE_PROJECT_REPONAME
            type: string
          build-number:
            default: ${CIRCLE_BUILD_NUM}
            description: |
              Artifactory build number, defaults to the value of $CIRCLE_BUILD_NUM
            type: string
          include-env:
            default: true
            description: |
              Collect environment variable details as part of Build Integration? For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-BuildIntegration-CollectingEnvironmentVariables
            type: boolean
          include-git:
            default: true
            description: |
              Collect git details as part of Build Integration? For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-BuildIntegration-AddingGitInformation
            type: boolean
        steps:
        - when:
            condition: <<parameters.include-git>>
            steps:
            - run:
                command: jfrog rt bag <<parameters.build-name>> <<parameters.build-number>>
                name: Collect git details with JFrog CLI
        - when:
            condition: <<parameters.include-env>>
            steps:
            - run:
                command: jfrog rt bce <<parameters.build-name>> <<parameters.build-number>>
                name: Collect environment variable details with JFrog CLI
        - run:
            command: jfrog rt bp <<parameters.build-name>> <<parameters.build-number>>
            name: Publish build details with JFrog CLI
      configure:
        description: Configure the JFrog CLI
        parameters:
          artifactory-key:
            default: ARTIFACTORY_API_KEY
            description: |
              Name of environment variable storing your Artifactory API key
            type: env_var_name
          artifactory-url:
            default: ARTIFACTORY_URL
            description: |
              Name of environment variable storing the URL of your Artifactory instance
            type: env_var_name
          artifactory-user:
            default: ARTIFACTORY_USER
            description: |
              Name of environment variable storing your Artifactory username
            type: env_var_name
        steps:
        - run:
            command: |
              : "${<<parameters.artifactory-url>>?Artifactory URL, API Key, and User \
                must be set as Environment variables before running this command.}"
              : "${<<parameters.artifactory-key>>?Artifactory URL, API Key, and User \
                must be set as Environment variables before running this command.}"
              : "${<<parameters.artifactory-user>>?Artifactory URL, API Key, and User \
                must be set as Environment variables before running this command.}"

              echo "configuring jfrog CLI with target ${<<parameters.artifactory-user>>}@${<<parameters.artifactory-url>>}"

              jfrog rt c \
                --user=${<<parameters.artifactory-user>>} \
                --url=${<<parameters.artifactory-url>>} \
                --apikey=${<<parameters.artifactory-key>>} \
                --interactive=false
            name: Configure JFrog CLI
      docker-login:
        description: |
          Log into a JFrog (or other) Docker registry
        parameters:
          artifactory-key:
            default: ARTIFACTORY_API_KEY
            description: |
              Name of environment variable storing your Artifactory API key
            type: env_var_name
          artifactory-user:
            default: ARTIFACTORY_USER
            description: |
              Name of environment variable storing your Artifactory username
            type: env_var_name
          docker-registry:
            description: |
              The URL to use for docker login, depends on web server configuration of Artifactory: https://jfrog.com/confluence/display/RTF/Getting+Started+with+Artifactory+as+a+Docker+Registry
            type: string
        steps:
        - run:
            command: |
              docker login -u $<<parameters.artifactory-user>> -p $<<parameters.artifactory-key>> <<parameters.docker-registry>>
            name: Log into JFrog Docker registry
      docker-publish:
        description: |
          Push an image to a JFrog Docker registry
        parameters:
          build-name:
            default: ${CIRCLE_PROJECT_REPONAME}
            description: |
              Artifactory build name, defaults to the value of $CIRCLE_PROJECT_REPONAME
            type: string
          build-number:
            default: ${CIRCLE_BUILD_NUM}
            description: |
              Artifactory build number, defaults to the value of $CIRCLE_BUILD_NUM
            type: string
          docker-tag:
            description: |
              Full named reference to Docker image (repo/name:tag)
            type: string
          repository:
            description: |
              Remote repository name in JFrog Artifactory
            type: string
        steps:
        - run:
            command: |
              jfrog rt dp <<parameters.docker-tag>> <<parameters.repository>> --build-name=<<parameters.build-name>> --build-number=<<parameters.build-number>>
            name: Docker push to JFrog registry
      install:
        description: Install the JFrog CLI
        steps:
        - run:
            command: |
              echo "Checking for existence of CLI"
              set +e
              jfrog -v
              if [ $? -gt 0 ]; then
                echo "Not found, installing latest"
                curl -fL https://getcli.jfrog.io | sh
                chmod a+x jfrog && sudo mv jfrog /usr/local/bin
              else
                echo "CLI exists, skipping install"
              fi
            name: Install JFrog CLI
      upload:
        description: |
          Upload files to Artifactory via `jfrog rt upload`. For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-UploadingFiles
        parameters:
          build-name:
            default: ${CIRCLE_PROJECT_REPONAME}
            description: |
              Artifactory build name, defaults to the value of $CIRCLE_PROJECT_REPONAME
            type: string
          build-number:
            default: ${CIRCLE_BUILD_NUM}
            description: |
              Artifactory build number, defaults to the value of $CIRCLE_BUILD_NUM
            type: string
          file-spec:
            default: ''
            description: |
              Absolute or relative path to a JFrog JSON File Spec. `use-file-spec` must be set to `true`.
            type: string
          source:
            default: ''
            description: |
              Absolute or relative path to artifacts which should be uploaded to Artifactory. Specify multiple artifacts by using wildcards.
            type: string
          spec-vars:
            default: ''
            description: |
              List of variables in the form of "key1=value1;key2=value2;..." to be replaced in the File Spec. `use-file-spec` must be set to `true`. In the File Spec, the variables should be used as follows: ${key1}.
            type: string
          target:
            default: ''
            description: |
              Target path in Artifactory for uploads, in the following format: [repository_name]/[repository_path]
            type: string
          use-file-spec:
            default: false
            description: |
              Use a JFrog JSON File Spec to configure Artifactory upload, rather than inline command arguments/options. Defaults to false. For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-UsingFileSpecs
            type: boolean
        steps:
        - when:
            condition: <<parameters.use-file-spec>>
            steps:
            - run:
                command: |
                  jfrog rt upload \
                    <<#parameters.source>>"<<parameters.source>>"<</parameters.source>> \
                    <<#parameters.target>><<parameters.target>><</parameters.target>> \
                    --spec=<<parameters.file-spec>> \
                    --spec-vars="<<parameters.spec-vars>>" \
                    --build-name=<<parameters.build-name>> \
                    --build-number=<<parameters.build-number>>
                name: Upload assets with JFrog CLI
        - unless:
            condition: <<parameters.use-file-spec>>
            steps:
            - run:
                command: |
                  jfrog rt upload "<<parameters.source>>" <<parameters.target>> \
                    --build-name=<<parameters.build-name>> \
                    --build-number=<<parameters.build-number>>
                name: Upload assets with JFrog CLI
    description: |
      Install, configure, and use the JFrog Artifactory CLI
    examples:
      build-integration-command:
        description: |
          Install and configure the JFrog CLI, then upload build information (includes git and environment info by default) to JFrog Artifactory
        usage:
          jobs:
            build:
              docker:
              - image: circleci/node:10
              steps:
              - checkout
              - artifactory/install
              - artifactory/configure
              - artifactory/build-integration
          orbs:
            artifactory: circleci/artifactory@1.0.0
          version: 2.1
      publish-docker-custom-build:
        description: |
          Use the `docker-publish` job to build and tag a Docker image, then push it to a JFrog Docker registry. This example includes a custom value for `docker-steps`, which allows you to override the default `docker build` logic. The value passed to the `docker-tag` parameter is  automatically stored as a job environment variable called `$DOCKERTAG`, so make sure to include that env var in your custom `docker build` logic.
        usage:
          orbs:
            artifactory: circleci/artifactory@1.0.0
          version: 2.1
          workflows:
            custom-docker-example:
              jobs:
              - artifactory/docker-publish:
                  docker-registry: orbdemos-docker-local.jfrog.io
                  docker-steps:
                  - run: docker build -t $DOCKERTAG docker-publish-assets
                  docker-tag: orbdemos-docker-local.jfrog.io/hello-world-custom:1.0-${CIRCLE_BUILD_NUM}
                  name: Docker Publish Custom Build
                  repository: docker-local
      publish-docker-simple:
        description: |
          Use the `docker-publish` job to build and tag a Docker image, then push it to a JFrog Docker registry. This example assumes that your Dockerfile is stored in the root of your repository.
        usage:
          orbs:
            artifactory: circleci/artifactory@1.0.0
          version: 2.1
          workflows:
            simple-docker-example:
              jobs:
              - artifactory/docker-publish:
                  docker-registry: orbdemos-docker-local.jfrog.io
                  docker-tag: orbdemos-docker-local.jfrog.io/hello-world:1.0-${CIRCLE_BUILD_NUM}
                  name: Docker Publish Simple
                  repository: docker-local
      upload-job:
        description: |
          Use the `upload` job to upload artifacts to JFrog's Artifactory
        usage:
          orbs:
            artifactory: circleci/artifactory@1.0.0
          version: 2.1
          workflows:
            publish:
              jobs:
              - artifactory/upload:
                  build-steps:
                  - run: mvn install -B
                  name: Publish Maven Jar
                  source: test/artifact.jar
                  target: repo/path
    executors:
      default:
        description: |
          The default executor for jobs in this orb. Specify your own Docker image or use the default (circleci/openjdk:8).
        docker:
        - image: <<parameters.docker-image>>
        parameters:
          docker-image:
            default: circleci/openjdk:8
            description: |
              Docker image to use in this executor, defaults to circleci/openjdk:8
            type: string
      machine:
        description: |
          A machine executor that can run Docker commands: https://circleci.com/docs/2.0/executor-types/#using-machine
        machine: true
    jobs:
      docker-publish:
        description: |
          Log into a JFrog Docker registry, build a Docker image, and push it to the registry
        environment:
          RAWTAG: <<parameters.docker-tag>>
        executor: machine
        parameters:
          artifactory-key:
            default: ARTIFACTORY_API_KEY
            description: |
              Name of environment variable storing your Artifactory API key
            type: env_var_name
          artifactory-user:
            default: ARTIFACTORY_USER
            description: |
              Name of environment variable storing your Artifactory username
            type: env_var_name
          build-integration:
            default: true
            description: Should Artifactory 'Build Publish' task be executed
            type: boolean
          build-name:
            default: ${CIRCLE_PROJECT_REPONAME}
            description: Name used in Artifactory Build Integration
            type: string
          build-number:
            default: ${CIRCLE_BUILD_NUM}
            description: Build Number used in Artifactory Build Integration
            type: string
          dependency-steps:
            default: []
            description: |
              Include any additional steps to collect dependency information before `jfrog rt bp` is executed.
            type: steps
          docker-registry:
            description: |
              The URL to use for docker login, depends on web server configuration of Artifactory: https://jfrog.com/confluence/display/RTF/Getting+Started+with+Artifactory+as+a+Docker+Registry
            type: string
          docker-steps:
            default:
            - run: docker build -t ${DOCKERTAG} .
            description: |
              Steps to Build and Tag image, defaults to `docker build -t ${DOCKERTAG} .`
            type: steps
          docker-tag:
            description: |
              Fully qualified(including reigstry) tag to use when issuing docker push commands. Will also be exposed to 'docker-steps' as a ${DOCKERTAG}
            type: string
          include-env:
            default: true
            description: |
              Collect environment variable details as part of Build Integration? For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-BuildIntegration-CollectingEnvironmentVariables
            type: boolean
          include-git:
            default: true
            description: |
              Collect git details as part of Build Integration? For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-BuildIntegration-AddingGitInformation
            type: boolean
          repository:
            description: |
              Remote repository name in JFrog Artifactory
            type: string
        steps:
        - checkout
        - install
        - configure
        - docker-login:
            artifactory-key: <<parameters.artifactory-key>>
            artifactory-user: <<parameters.artifactory-user>>
            docker-registry: <<parameters.docker-registry>>
        - run: eval echo "export DOCKERTAG=${RAWTAG}" >> $BASH_ENV
        - steps: <<parameters.dependency-steps>>
        - steps: << parameters.docker-steps >>
        - docker-publish:
            build-name: <<parameters.build-name>>
            build-number: <<parameters.build-number>>
            docker-tag: <<parameters.docker-tag>>
            repository: <<parameters.repository>>
        - when:
            condition: <<parameters.build-integration>>
            steps:
            - build-integration:
                build-name: <<parameters.build-name>>
                build-number: <<parameters.build-number>>
                include-env: <<parameters.include-env>>
                include-git: <<parameters.include-git>>
      upload:
        description: Upload artifacts to Artifactory
        docker:
        - image: <<parameters.docker>>
        parameters:
          build-integration:
            default: true
            description: Should Artifactory 'Build Publish' task be executed
            type: boolean
          build-name:
            default: ${CIRCLE_PROJECT_REPONAME}
            description: |
              Artifactory build name, defaults to the value of $CIRCLE_PROJECT_REPONAME
            type: string
          build-number:
            default: ${CIRCLE_BUILD_NUM}
            description: |
              Artifactory build number, defaults to the value of $CIRCLE_BUILD_NUM
            type: string
          build-steps:
            default: []
            description: |
              Steps to generate artifacts. Alternately provide `workspace-path`.
            type: steps
          docker:
            default: circleci/openjdk:8
            description: Docker image to use for build
            type: string
          file-spec:
            default: ''
            description: |
              Absolute or relative path to a JFrog JSON File Spec. To provide a File Spec, the `use-file-spec` parameter must be set to `true`.
            type: string
          include-env:
            default: true
            type: boolean
          include-git:
            default: true
            type: boolean
          source:
            default: ''
            description: |
              Absolute or relative path to artifacts which should be uploaded to Artifactory. Specify multiple artifacts by using wildcards.
            type: string
          spec-vars:
            default: ''
            description: |
              List of variables in the form of "key1=value1;key2=value2;..." to be replaced in the File Spec. `use-file-spec` must be set to `true`. In the File Spec, the variables should be used as follows: ${key1}.
            type: string
          target:
            default: ''
            description: |
              Target path in Artifactory for uploads, in the following format: [repository_name]/[repository_path]
            type: string
          use-file-spec:
            default: false
            description: |
              Use a JFrog JSON File Spec to configure Artifactory upload, rather than inline command arguments/options. Defaults to false. For details, see https://jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory#CLIforJFrogArtifactory-UsingFileSpecs
            type: boolean
          workspace-path:
            default: ''
            description: |
              The key of a workflow workspace which contains artifacts. Alternately provide `build-steps`
            type: string
        steps:
        - checkout
        - when:
            condition: <<parameters.build-steps>>
            steps: <<parameters.build-steps>>
        - when:
            condition: <<parameters.workspace-path>>
            steps:
            - attach_workspace:
                at: <<parameters.workspace-path>>
        - install
        - configure
        - upload:
            build-name: <<parameters.build-name>>
            build-number: <<parameters.build-number>>
            file-spec: <<parameters.file-spec>>
            source: <<parameters.source>>
            spec-vars: <<parameters.spec-vars>>
            target: <<parameters.target>>
            use-file-spec: <<parameters.use-file-spec>>
        - when:
            condition: <<parameters.build-integration>>
            steps:
            - build-integration:
                build-name: <<parameters.build-name>>
                build-number: <<parameters.build-number>>
                include-env: <<parameters.include-env>>
                include-git: <<parameters.include-git>>
    version: 2.1
  aws-cli:
    version: 2.1
    description: |
      Install and configure the AWS command-line interface (awscli)
    executors:
      default:
        description: |
          The Debian-based Docker container to use when
          installing/configuring the AWS CLI
        parameters:
          python-version:
            type: string
            default: '2.7'
          debian-release:
            type: string
            default: stretch
        docker:
        - image: circleci/python:<<parameters.python-version>>-<<parameters.debian-release>>
    commands:
      install:
        description: |
          Install the AWS CLI via pip.
        steps:
        - run:
            name: Install AWS CLI
            command: |
              export PIP=$(which pip pip3 | head -1)
              if [[ -n $PIP ]]; then
                if which sudo > /dev/null; then
                  sudo $PIP install awscli --upgrade
                else
                  # This installs the AWS CLI to ~/.local/bin. Make sure that ~/.local/bin is in your $PATH.
                  $PIP install awscli --upgrade --user
                fi
              elif [[ $(which unzip curl | wc -l) -eq 2 ]]; then
                cd
                curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
                unzip awscli-bundle.zip
                if which sudo > /dev/null; then
                  sudo ~/awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
                else
                  # This installs the AWS CLI to the default location (~/.local/lib/aws) and create a symbolic link (symlink) at ~/bin/aws. Make sure that ~/bin is in your $PATH.
                  awscli-bundle/install -b ~/bin/aws
                fi
                rm -rf awscli-bundle*
                cd -
              else
                echo "Unable to install AWS CLI. Please install pip."
                exit 1
              fi
      configure:
        description: |
          Configure and store AWS credentials in
          ~/.aws/credentials and ~/.aws/config
        parameters:
          profile-name:
            description: Profile name to be configured.
            type: string
            default: default
          aws-access-key-id:
            description: |
              AWS access key id for IAM role. Set this to the name of
              the environment variable you will use to hold this
              value, i.e. AWS_ACCESS_KEY.
            type: env_var_name
            default: AWS_ACCESS_KEY_ID
          aws-secret-access-key:
            description: |
              AWS secret key for IAM role. Set this to the name of
              the environment variable you will use to hold this
              value, i.e. $AWS_SECRET_ACCESS_KEY.
            type: env_var_name
            default: AWS_SECRET_ACCESS_KEY
          aws-region:
            description: |
              Env var of AWS region to operate in
              (defaults to AWS_DEFAULT_REGION)
            type: env_var_name
            default: AWS_DEFAULT_REGION
          configure-default-region:
            description: |
              Some AWS actions don't require a region; set this to false if you do not want to store a default region in ~/.aws/config
            type: boolean
            default: true
        steps:
        - run:
            name: Configure AWS Access Key ID
            command: |
              aws configure set aws_access_key_id \
              $<<parameters.aws-access-key-id>> \
              --profile <<parameters.profile-name>>
        - run:
            name: Configure AWS Secret Access Key
            command: |
              aws configure set aws_secret_access_key \
              $<<parameters.aws-secret-access-key>> \
              --profile <<parameters.profile-name>>
        - when:
            condition: <<parameters.configure-default-region>>
            steps:
            - run:
                name: Configure AWS default region
                command: |
                  aws configure set region $<<parameters.aws-region>> \
                  --profile <<parameters.profile-name>>
  aws-ecr:
    commands:
      build-and-push-image:
        description: |
          Install AWS CLI, if needed, and configure. Log into Amazon ECR and push image to repository. Requires environment variables for AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY. We recommend these be saved in a Project (https://circleci.com/docs/2.0/env-vars/#setting-an-environment-variable-in-a-project) or in Contexts (https://circleci.com/docs/2.0/contexts).
        parameters:
          account-url:
            default: AWS_ECR_ACCOUNT_URL
            description: |
              Env var storing Amazon ECR account URL that maps to an AWS account, e.g. {awsAccountNum}.dkr.ecr.us-west-2.amazonaws.com defaults to AWS_ECR_ACCOUNT_URL
            type: env_var_name
          attach-workspace:
            default: false
            description: |
              Boolean for whether or not to attach to an existing workspace. Default is false.
            type: boolean
          aws-access-key-id:
            default: AWS_ACCESS_KEY_ID
            description: |
              AWS access key id for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_ACCESS_KEY.
            type: env_var_name
          aws-secret-access-key:
            default: AWS_SECRET_ACCESS_KEY
            description: |
              AWS secret key for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_SECRET_ACCESS_KEY.
            type: env_var_name
          checkout:
            default: true
            description: |
              Boolean for whether or not to checkout as a first step. Default is true.
            type: boolean
          create-repo:
            default: false
            description: Should the repo be created if it does not exist?
            type: boolean
          dockerfile:
            default: Dockerfile
            description: Name of dockerfile to use. Defaults to Dockerfile.
            type: string
          executor:
            default: default
            description: executor to use for this job
            type: executor
          extra-build-args:
            default: ''
            description: |
              Extra flags to pass to docker build. For examples, see https://docs.docker.com/engine/reference/commandline/build
            type: string
          no-output-timeout:
            default: 10m
            description: |
              The amount of time to allow the docker build command to run before timing out (default is `10m`)
            type: string
          path:
            default: .
            description: Path to the directory containing your Dockerfile and build context. Defaults to . (working directory).
            type: string
          profile-name:
            default: default
            description: AWS profile name to be configured.
            type: string
          region:
            default: AWS_REGION
            description: |
              Name of env var storing your AWS region information, defaults to AWS_REGION
            type: env_var_name
          repo:
            description: Name of an Amazon ECR repository
            type: string
          setup-remote-docker:
            default: false
            description: |
              Setup and use CircleCI's remote Docker environment for Docker and docker-compose commands? Not required if using the default executor
            type: boolean
          tag:
            default: latest
            description: A comma-separated string containing docker image tags to build and push (default = latest)
            type: string
          workspace-root:
            default: .
            description: |
              Workspace root path that is either an absolute path or a path relative to the working directory. Defaults to '.' (the working directory)
            type: string
        steps:
        - when:
            condition: <<parameters.checkout>>
            steps:
            - checkout
        - aws-cli/install
        - aws-cli/configure:
            aws-access-key-id: <<parameters.aws-access-key-id>>
            aws-region: <<parameters.region>>
            aws-secret-access-key: <<parameters.aws-secret-access-key>>
            profile-name: <<parameters.profile-name>>
        - when:
            condition: <<parameters.attach-workspace>>
            steps:
            - attach_workspace:
                at: <<parameters.workspace-root>>
        - when:
            condition: <<parameters.setup-remote-docker>>
            steps:
            - setup_remote_docker
        - ecr-login:
            region: <<parameters.region>>
        - build-image:
            account-url: <<parameters.account-url>>
            dockerfile: <<parameters.dockerfile>>
            extra-build-args: <<parameters.extra-build-args>>
            no-output-timeout: <<parameters.no-output-timeout>>
            path: <<parameters.path>>
            repo: <<parameters.repo>>
            tag: <<parameters.tag>>
        - when:
            condition: <<parameters.create-repo>>
            steps:
            - run: |
                aws ecr describe-repositories --profile <<parameters.profile-name>> --region $<<parameters.region>> --repository-names <<parameters.repo>> > /dev/null 2>&1 || \
                aws ecr create-repository --profile <<parameters.profile-name>> --region $<<parameters.region>> --repository-name <<parameters.repo>>
        - push-image:
            account-url: <<parameters.account-url>>
            repo: <<parameters.repo>>
            tag: <<parameters.tag>>
      build-image:
        description: Build a docker image
        parameters:
          account-url:
            default: AWS_ECR_ACCOUNT_URL
            description: |
              The Amazon ECR account URL that maps to an AWS account, e.g. {awsAccountNum}.dkr.ecr.us-west-2.amazonaws.com
            type: env_var_name
          dockerfile:
            default: Dockerfile
            description: Name of dockerfile to use. Defaults to Dockerfile.
            type: string
          extra-build-args:
            default: ''
            description: |
              Extra flags to pass to docker build. For examples, see https://docs.docker.com/engine/reference/commandline/build
            type: string
          no-output-timeout:
            default: 10m
            description: The amount of time to allow the docker command to run before timing out.
            type: string
          path:
            default: .
            description: Path to the directory containing your Dockerfile and build context. Defaults to . (working directory).
            type: string
          repo:
            description: Name of an Amazon ECR repository
            type: string
          tag:
            default: latest
            description: A comma-separated string containing docker image tags (default = latest)
            type: string
        steps:
        - run:
            command: |
              docker_tag_args=""
              IFS="," read -ra DOCKER_TAGS \<<< "<< parameters.tag >>"
              for tag in "${DOCKER_TAGS[@]}"; do
                docker_tag_args="$docker_tag_args -t $<<parameters.account-url>>/<<parameters.repo>>:$tag"
              done
              docker build \
                <<#parameters.extra-build-args>><<parameters.extra-build-args>><</parameters.extra-build-args>> \
                -f <<parameters.dockerfile>> \
                $docker_tag_args \
                <<parameters.path>>
            name: Build docker image
            no_output_timeout: <<parameters.no-output-timeout>>
      ecr-login:
        description: Authenticate into the Amazon ECR service
        parameters:
          region:
            default: AWS_REGION
            description: |
              Name of env var storing your AWS region information, defaults to AWS_REGION
            type: env_var_name
        steps:
        - run:
            command: |
              # aws ecr get-login returns a login command w/ a temp token
              LOGIN_COMMAND=$(aws ecr get-login --no-include-email --region $<<parameters.region>>)

              # save it to an env var & use that env var to login
              $LOGIN_COMMAND
            name: Log into Amazon ECR
      ecr-login-for-secondary-account:
        description: Authenticate into the Amazon ECR service
        parameters:
          account-id:
            default: AWS_ECR_REPO_ACCOUNT_ID
            description: |
              Name of environment variable storing the Amazon ECR repository's account ID
            type: env_var_name
          region:
            default: AWS_REGION
            description: |
              Name of environment variable storing AWS region information, defaults to AWS_REGION
            type: env_var_name
        steps:
        - run:
            command: |
              # aws ecr get-login returns a login command w/ a temp token
              LOGIN_COMMAND=$(aws ecr get-login --no-include-email --region $<<parameters.region>> --registry-ids $<<parameters.account-id>>)

              # save it to an env var & use that env var to login
              $LOGIN_COMMAND
            name: Log into Amazon ECR
      push-image:
        description: Push a container image to the Amazon ECR registry
        parameters:
          account-url:
            default: AWS_ECR_ACCOUNT_URL
            description: |
              Env var storing Amazon ECR account URL that maps to an AWS account, e.g. {awsAccountNum}.dkr.ecr.us-west-2.amazonaws.com defaults to AWS_ECR_ACCOUNT_URL
            type: env_var_name
          repo:
            description: Name of an Amazon ECR repository
            type: string
          tag:
            default: latest
            description: A comma-separated string containing docker image tags (default = latest)
            type: string
        steps:
        - run:
            command: |
              IFS="," read -ra DOCKER_TAGS \<<< "<< parameters.tag >>"
              for tag in "${DOCKER_TAGS[@]}"; do
                docker push $<<parameters.account-url>>/<<parameters.repo>>:${tag}
              done
            name: Push image to Amazon ECR
    description: |
      Build images and push them to the Amazon Elastic Container Registry. See this orb's source: https://github.com/circleci-public/aws-ecr-orb
    examples:
      simple-build-and-push:
        description: Log into AWS, build and push image to Amazon ECR
        usage:
          orbs:
            aws-ecr: circleci/aws-ecr@x.y.z
          version: 2.1
          workflows:
            build_and_push_image:
              jobs:
              - aws-ecr/build-and-push-image:
                  account-url: AWS_ECR_ACCOUNT_URL_ENV_VAR_NAME
                  aws-access-key-id: ACCESS_KEY_ID_ENV_VAR_NAME
                  aws-secret-access-key: SECRET_ACCESS_KEY_ENV_VAR_NAME
                  context: myContext
                  create-repo: true
                  dockerfile: myDockerfile
                  path: pathToMyDockerfile
                  profile-name: myProfileName
                  region: AWS_REGION_ENV_VAR_NAME
                  repo: myECRRepository
                  tag: latest,myECRRepoTag
    executors:
      default:
        description: |
          CircleCI's Ubuntu-based machine executor VM: https://circleci.com/docs/2.0/executor-types/#using-machine
        machine:
          image: <<parameters.image>>
        parameters:
          image:
            default: ubuntu-1604:201903-01
            type: string
    jobs:
      build-and-push-image:
        description: |
          Install AWS CLI, if needed, and configure. Log into Amazon ECR and push image to repository. Requires environment variables for AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY. We recommend these be saved in a Project (https://circleci.com/docs/2.0/env-vars/#setting-an-environment-variable-in-a-project) or in Contexts (https://circleci.com/docs/2.0/contexts).
        executor: <<parameters.executor>>
        parameters:
          account-url:
            default: AWS_ECR_ACCOUNT_URL
            description: |
              Env var storing Amazon ECR account URL that maps to an AWS account, e.g. {awsAccountNum}.dkr.ecr.us-west-2.amazonaws.com defaults to AWS_ECR_ACCOUNT_URL
            type: env_var_name
          attach-workspace:
            default: false
            description: |
              Boolean for whether or not to attach to an existing workspace. Default is false.
            type: boolean
          aws-access-key-id:
            default: AWS_ACCESS_KEY_ID
            description: |
              AWS access key id for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_ACCESS_KEY.
            type: env_var_name
          aws-secret-access-key:
            default: AWS_SECRET_ACCESS_KEY
            description: |
              AWS secret key for IAM role. Set this to the name of the environment variable you will set to hold this value, i.e. AWS_SECRET_ACCESS_KEY.
            type: env_var_name
          checkout:
            default: true
            description: |
              Boolean for whether or not to checkout as a first step. Default is true.
            type: boolean
          create-repo:
            default: false
            description: Should the repo be created if it does not exist?
            type: boolean
          dockerfile:
            default: Dockerfile
            description: Name of dockerfile to use. Defaults to Dockerfile.
            type: string
          executor:
            default: default
            description: executor to use for this job
            type: executor
          extra-build-args:
            default: ''
            description: |
              Extra flags to pass to docker build. For examples, see https://docs.docker.com/engine/reference/commandline/build
            type: string
          path:
            default: .
            description: Path to the directory containing your Dockerfile and build context. Defaults to . (working directory).
            type: string
          profile-name:
            default: default
            description: AWS profile name to be configured.
            type: string
          region:
            default: AWS_REGION
            description: |
              Name of env var storing your AWS region information, defaults to AWS_REGION
            type: env_var_name
          repo:
            description: Name of an Amazon ECR repository
            type: string
          setup-remote-docker:
            default: false
            description: |
              Setup and use CircleCI's remote Docker environment for Docker and docker-compose commands? Not required if using the default executor
            type: boolean
          tag:
            default: latest
            description: A comma-separated string containing docker image tags to build and push (default = latest)
            type: string
          workspace-root:
            default: .
            description: |
              Workspace root path that is either an absolute path or a path relative to the working directory. Defaults to '.' (the working directory)
            type: string
        steps:
        - build-and-push-image:
            account-url: <<parameters.account-url>>
            attach-workspace: <<parameters.attach-workspace>>
            aws-access-key-id: <<parameters.aws-access-key-id>>
            aws-secret-access-key: <<parameters.aws-secret-access-key>>
            checkout: <<parameters.checkout>>
            create-repo: <<parameters.create-repo>>
            dockerfile: <<parameters.dockerfile>>
            extra-build-args: <<parameters.extra-build-args>>
            path: <<parameters.path>>
            profile-name: <<parameters.profile-name>>
            region: <<parameters.region>>
            repo: <<parameters.repo>>
            setup-remote-docker: <<parameters.setup-remote-docker>>
            tag: <<parameters.tag>>
            workspace-root: <<parameters.workspace-root>>
    orbs:
      aws-cli:
        version: 2.1
        description: |
          Install and configure the AWS command-line interface (awscli)
        executors:
          default:
            description: |
              The Debian-based Docker container to use when
              installing/configuring the AWS CLI
            parameters:
              python-version:
                type: string
                default: '2.7'
              debian-release:
                type: string
                default: stretch
            docker:
            - image: circleci/python:<<parameters.python-version>>-<<parameters.debian-release>>
        commands:
          install:
            description: |
              Install the AWS CLI via pip.
            steps:
            - run:
                name: Install AWS CLI
                command: |
                  export PIP=$(which pip pip3 | head -1)
                  if [[ -n $PIP ]]; then
                    if which sudo > /dev/null; then
                      sudo $PIP install awscli --upgrade
                    else
                      # This installs the AWS CLI to ~/.local/bin. Make sure that ~/.local/bin is in your $PATH.
                      $PIP install awscli --upgrade --user
                    fi
                  elif [[ $(which unzip curl | wc -l) -eq 2 ]]; then
                    cd
                    curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
                    unzip awscli-bundle.zip
                    if which sudo > /dev/null; then
                      sudo ~/awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
                    else
                      # This installs the AWS CLI to the default location (~/.local/lib/aws) and create a symbolic link (symlink) at ~/bin/aws. Make sure that ~/bin is in your $PATH.
                      awscli-bundle/install -b ~/bin/aws
                    fi
                    rm -rf awscli-bundle*
                    cd -
                  else
                    echo "Unable to install AWS CLI. Please install pip."
                    exit 1
                  fi
          configure:
            description: |
              Configure and store AWS credentials in
              ~/.aws/credentials and ~/.aws/config
            parameters:
              profile-name:
                description: Profile name to be configured.
                type: string
                default: default
              aws-access-key-id:
                description: |
                  AWS access key id for IAM role. Set this to the name of
                  the environment variable you will use to hold this
                  value, i.e. AWS_ACCESS_KEY.
                type: env_var_name
                default: AWS_ACCESS_KEY_ID
              aws-secret-access-key:
                description: |
                  AWS secret key for IAM role. Set this to the name of
                  the environment variable you will use to hold this
                  value, i.e. $AWS_SECRET_ACCESS_KEY.
                type: env_var_name
                default: AWS_SECRET_ACCESS_KEY
              aws-region:
                description: |
                  Env var of AWS region to operate in
                  (defaults to AWS_DEFAULT_REGION)
                type: env_var_name
                default: AWS_DEFAULT_REGION
              configure-default-region:
                description: |
                  Some AWS actions don't require a region; set this to false if you do not want to store a default region in ~/.aws/config
                type: boolean
                default: true
            steps:
            - run:
                name: Configure AWS Access Key ID
                command: |
                  aws configure set aws_access_key_id \
                  $<<parameters.aws-access-key-id>> \
                  --profile <<parameters.profile-name>>
            - run:
                name: Configure AWS Secret Access Key
                command: |
                  aws configure set aws_secret_access_key \
                  $<<parameters.aws-secret-access-key>> \
                  --profile <<parameters.profile-name>>
            - when:
                condition: <<parameters.configure-default-region>>
                steps:
                - run:
                    name: Configure AWS default region
                    command: |
                      aws configure set region $<<parameters.aws-region>> \
                      --profile <<parameters.profile-name>>
    version: 2.1
version: '2.1'

